{"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow.python.client import device_lib\ndevice_lib.list_local_devices()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6236N1ibwOLh","outputId":"9ce4f55b-98f3-4eb8-e851-4e3c11f90e50","execution":{"iopub.status.busy":"2023-02-12T06:11:51.578168Z","iopub.execute_input":"2023-02-12T06:11:51.579061Z","iopub.status.idle":"2023-02-12T06:11:51.592438Z","shell.execute_reply.started":"2023-02-12T06:11:51.579017Z","shell.execute_reply":"2023-02-12T06:11:51.591338Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2023-02-12 06:11:51.581615: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-12 06:11:51.582879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-12 06:11:51.583849: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-12 06:11:51.584625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-12 06:11:51.585298: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-12 06:11:51.585875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"[name: \"/device:CPU:0\"\n device_type: \"CPU\"\n memory_limit: 268435456\n locality {\n }\n incarnation: 11097147352090211880,\n name: \"/device:GPU:0\"\n device_type: \"GPU\"\n memory_limit: 16149905408\n locality {\n   bus_id: 1\n   links {\n   }\n }\n incarnation: 15842881770489263802\n physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"]"},"metadata":{}}]},{"cell_type":"code","source":"!pip install pyvi","metadata":{"id":"ja4vZYNId7Nj","colab":{"base_uri":"https://localhost:8080/"},"outputId":"608f5fe0-6e6d-4db4-bf09-d3b00c0cf7b0","execution":{"iopub.status.busy":"2023-02-12T06:11:51.593892Z","iopub.execute_input":"2023-02-12T06:11:51.594602Z","iopub.status.idle":"2023-02-12T06:12:01.079135Z","shell.execute_reply.started":"2023-02-12T06:11:51.594561Z","shell.execute_reply":"2023-02-12T06:12:01.078000Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pyvi in /opt/conda/lib/python3.7/site-packages (0.1.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from pyvi) (1.0.2)\nRequirement already satisfied: sklearn-crfsuite in /opt/conda/lib/python3.7/site-packages (from pyvi) (0.3.6)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->pyvi) (3.1.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->pyvi) (1.0.1)\nRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->pyvi) (1.7.3)\nRequirement already satisfied: numpy>=1.14.6 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->pyvi) (1.21.6)\nRequirement already satisfied: python-crfsuite>=0.8.3 in /opt/conda/lib/python3.7/site-packages (from sklearn-crfsuite->pyvi) (0.9.9)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sklearn-crfsuite->pyvi) (1.15.0)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from sklearn-crfsuite->pyvi) (0.9.0)\nRequirement already satisfied: tqdm>=2.0 in /opt/conda/lib/python3.7/site-packages (from sklearn-crfsuite->pyvi) (4.64.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from pyvi import ViTokenizer, ViPosTagger\nimport numpy as np\nimport pandas as pd\nimport re\nimport string\nimport gensim\nimport sklearn\nimport tensorflow as tf\nfrom sklearn import svm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.metrics import classification_report\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom tensorflow.keras.layers import *\nfrom keras.layers import *\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.models import Model\nfrom keras.metrics import sparse_categorical_accuracy\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn import preprocessing","metadata":{"id":"wQI23zcBgc6W","execution":{"iopub.status.busy":"2023-02-12T06:12:01.081034Z","iopub.execute_input":"2023-02-12T06:12:01.081381Z","iopub.status.idle":"2023-02-12T06:12:01.091414Z","shell.execute_reply.started":"2023-02-12T06:12:01.081351Z","shell.execute_reply":"2023-02-12T06:12:01.090014Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def changeToOther(topic=''):\n    top_9_subtopic = csv['Topic'].value_counts()[:9].index.tolist()\n    if topic not in top_9_subtopic: return 'Other'\n    return topic","metadata":{"execution":{"iopub.status.busy":"2023-02-09T07:54:32.802299Z","iopub.execute_input":"2023-02-09T07:54:32.803006Z","iopub.status.idle":"2023-02-09T07:54:32.812609Z","shell.execute_reply.started":"2023-02-09T07:54:32.802965Z","shell.execute_reply":"2023-02-09T07:54:32.810860Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Load dataset\ncsv = pd.read_csv('/kaggle/input/vne-sub-topic-1/Vne_sub_topic_1.csv')\ncsv['Topic'] = csv['Topic'].apply(lambda x: changeToOther(x))\ncsv = csv.sample(frac=1)\ncsv[csv['Topic'] == 'Other'] = csv[csv['Topic'] == 'Other'][:500]\ncsv = csv.dropna()\ncsv['Topic'].value_counts()","metadata":{"id":"ii47DbENfUEv","execution":{"iopub.status.busy":"2023-02-09T07:54:32.815226Z","iopub.execute_input":"2023-02-09T07:54:32.815638Z","iopub.status.idle":"2023-02-09T07:54:36.198019Z","shell.execute_reply.started":"2023-02-09T07:54:32.815592Z","shell.execute_reply":"2023-02-09T07:54:36.197029Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"Other                      500\nthe-thao_bong-da           300\ngiao-duc_tin-tuc           296\nsuc-khoe_tin-tuc           292\nthe-thao_cac-mon-khac      292\ngiai-tri_gioi-sao          271\ndu-lich_diem-den           264\nthe-thao_world-cup-2022    259\nkhoa-hoc_tin-tuc           253\nsuc-khoe_cac-benh          246\nName: Topic, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"dataset = csv[['Content', 'Topic']]\ndataset = dataset.sample(frac=1)\ndatanewscontent = dataset['Content']\nlabelnews = dataset['Topic']\n# x = labelnews.value_counts()\n# print(x)","metadata":{"id":"vONvcCEVgbsr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bfcc1a84-f2a3-4fdc-9b0b-da747eca7f64","execution":{"iopub.status.busy":"2023-02-09T07:54:36.199298Z","iopub.execute_input":"2023-02-09T07:54:36.201003Z","iopub.status.idle":"2023-02-09T07:54:36.208092Z","shell.execute_reply.started":"2023-02-09T07:54:36.200963Z","shell.execute_reply":"2023-02-09T07:54:36.207128Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(datanewscontent[:5])\nprint(labelnews[:5])","metadata":{"execution":{"iopub.status.busy":"2023-02-09T07:55:12.936415Z","iopub.execute_input":"2023-02-09T07:55:12.936828Z","iopub.status.idle":"2023-02-09T07:55:12.943787Z","shell.execute_reply.started":"2023-02-09T07:55:12.936782Z","shell.execute_reply":"2023-02-09T07:55:12.942628Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"1603    14 đội sẽ đá vòng tròn một lượt tính điểm, rồi...\n900     123 phim của 50 quốc gia và vùng lãnh thổ sẽ t...\n4127    Hầu hết trường hợp dị ứng thực phẩm có liên qu...\n1933    Một CĐV có ảnh hưởng trên mạng xã hội Trung Qu...\n4056    Cách bài tập thở bằng mũi, bụng giúp tăng lượn...\nName: Content, dtype: object\n1603           the-thao_bong-da\n900                       Other\n4127          suc-khoe_cac-benh\n1933    the-thao_world-cup-2022\n4056          suc-khoe_cac-benh\nName: Topic, dtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"# Text preprocessing \ndef text_preprocessing(text=''):\n  text = text.lower()\n  # text = re.sub('[0-9]+',' ',text)\n  text = text.translate(text.maketrans(string.punctuation, ' '*len(string.punctuation)))\n  text = re.sub('\\s+', ' ', text)\n  return text","metadata":{"id":"g4rM6Jpz2gDh","execution":{"iopub.status.busy":"2023-02-09T07:56:33.173270Z","iopub.execute_input":"2023-02-09T07:56:33.173636Z","iopub.status.idle":"2023-02-09T07:56:33.179296Z","shell.execute_reply.started":"2023-02-09T07:56:33.173603Z","shell.execute_reply":"2023-02-09T07:56:33.177998Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"datanews = []\nfor d in datanewscontent:\n    e=ViTokenizer.tokenize(text_preprocessing(d))\n    datanews.append(e)","metadata":{"id":"WoI5KfZey7Z2","execution":{"iopub.status.busy":"2023-02-09T07:56:33.465293Z","iopub.execute_input":"2023-02-09T07:56:33.465712Z","iopub.status.idle":"2023-02-09T07:57:05.418920Z","shell.execute_reply.started":"2023-02-09T07:56:33.465676Z","shell.execute_reply":"2023-02-09T07:57:05.417820Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"datanews[:5]","metadata":{"execution":{"iopub.status.busy":"2023-02-09T07:57:24.065122Z","iopub.execute_input":"2023-02-09T07:57:24.066116Z","iopub.status.idle":"2023-02-09T07:57:24.073854Z","shell.execute_reply.started":"2023-02-09T07:57:24.066074Z","shell.execute_reply":"2023-02-09T07:57:24.072729Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"['14 đội sẽ đá vòng_tròn một lượt tính điểm rồi chia làm hai nhóm đá tranh chức vô_địch và đua trụ hạng ở giải đoạn hai v league 2023 thay_đổi thể_thức này nằm trong dự_kiến kế_hoạch thi_đấu mùa giải bóng_đá chuyên_nghiệp quốc_gia 2023 được công_ty cổ_phần bóng_đá chuyên_nghiệp việt nam vpf công_bố hôm_nay v league 2023 sẽ khai_mạc vào ngày 3 2 và kết_thúc vào ngày 20 8 đây sẽ là mùa giải ngắn nhất lịch_sử kể từ khi giải vđqg chuyên_nghiệp ra_đời năm 2000 ban tổ_chức rút ngắn thời_gian tổ_chức v league 2023 để chuẩn_bị cho việc mùa giải kế_tiếp sẽ chuyển sang đá vắt qua hai năm giống các giải châu âu v league 2023 không thi_đấu vòng_tròn hai lượt tính điểm chọn đội vô_địch như mùa giải năm nay các đội sẽ đá vòng_tròn một lượt tính điểm ở giai_đoạn một sau đó 6 đội đứng trên sẽ đá giai_đoạn hai tranh chức vô_địch 8 đội đứng dưới sẽ đua trụ hạng thể_thức thi_đấu này từng được vpf áp_dụng ở mùa 2020 rồi 2021 mùa bị huỷ sau vòng 12 do covid 19 v league 2023 cũng sẽ tăng số đội lên 14 trước đó giải còn 13 đội khi quảng_ninh giải_thể năm 2021 hai tân_binh của v league 2023 là công_an nhân_dân và khánh hòa v league 2022 chỉ có một suất xuống hạng và ba đội đang đứng trước nguy_cơ này là sài_gòn nam định và hà tĩnh mùa giải 2023 của bóng_đá việt_nam sẽ bắt_đầu bằng trận tranh siêu cup quốc_gia vào ngày 29 1 sau v league giải hạng nhất sẽ khai_mạc vào ngày 4 2 và cup quốc_gia bắt_đầu ngày 18 3',\n '123 phim của 50 quốc_gia và vùng lãnh_thổ sẽ tham_dự liên_hoan_phim quốc_tế hà nội lần sáu từ ngày 8 đến 12 11 ông vi kiến thành cục_trưởng điện_ảnh cho biết hội_đồng tuyển_chọn đưa ra danh_sách gồm 11 phim dài 20 phim ngắn dự thi ngoài ra ban tổ_chức phát bảy phim trong chương_trình tiêu_điểm điện_ảnh hàn quốc 63 phim trong chương_trình toàn_cảnh điện_ảnh thế_giới 22 phim việt nam đương_đại ban tổ_chức chưa công_bố thành_viên ban giám_khảo khách mời quốc_tế phim duy_nhất của việt nam tranh giải là hoa nhài đạo_diễn đặng nhật minh sản_xuất năm nay tác_phẩm lấy cảm_hứng từ câu ca_dao chẳng thơm cũng thể hoa nhài dẫu không thanh_lịch cũng người tràng an đạo_diễn nói ông muốn làm tác_phẩm điện_ảnh kinh_phí thấp về người hà_nội trong bối_cảnh thành_phố đã trải qua nhiều đổi_thay khi dòng người tứ_xứ đổ về ngày_càng nhiều phim có nhiều lát cắt xoay quanh mối quan_hệ giữa người với người những nhân_vật như em bé đánh giày từ quê ra tỉnh_lẻ ông thợ cắt tóc ông giáo gốc hà_nội góp_phần tạo nên bức tranh đô_thị nhộn_nhịp bình_dị ở tuổi 84 đặng nhật minh nói đây là tác_phẩm cuối_cùng của ông năm nay ban tổ_chức giữ nguyên các giải_thưởng chính gồm phim xuất_sắc đạo_diễn_xuất_sắc nam_nữ chính xuất_sắc ở hai hạng_mục là phim dài và phim ngắn các tác_phẩm dự thi được chiếu miễn_phí ở trung_tâm chiếu_phim quốc_gia 87 láng hạ rạp cgv vincom center 54 nguyễn chí thanh và bhd star cinema trung_tâm thương_mại vincom phạm ngọc_thạch lễ khai_mạc diễn ra tại cung_văn_hóa hữu_nghị việt xô hà_nội ngày 8 11 ngoài hoạt_động chiếu_phim ban tổ_chức thực_hiện triển_lãm bối_cảnh quay_phim là các di_tích di_sản văn_hóa của hà nội giới_thiệu hơn 200 hình_ảnh trong các phim việt nam quay tại thủ_đô các đại_biểu nhà làm phim trẻ sẽ có cơ_hội tham_gia một_số hội_thảo tọa_đàm liên_quan điện_ảnh ban tổ_chức dự_kiến mời 800 khách trong đó có khoảng 100 khách quốc_tế ông vi kiến thành cho biết do ảnh_hưởng đại_dịch họ nhận được ít tiền_tài_trợ hơn liên_hoan_phim quốc_tế hà nội lần năm 2018 vì_thế các sự_kiện khai_mạc bế_mạc và một_số hoạt_động bên lề không hoành_tráng như trước liên_hoan_phim quốc_tế hà_nội viết tắt là haniff được tổ_chức lần đầu năm 2010 do cục điện_ảnh bộ văn_hóa thể_thao và du_lịch phối_hợp ủy_ban nhân_dân thành_phố hà_nội phối_hợp tổ_chức qua năm lần tổ_chức sự_kiện thu_hút nhiều tác_phẩm nghệ_sĩ từ nhiều nền điện_ảnh thế_giới đồng_thời góp_phần quảng_bá điện_ảnh việt_nam',\n 'hầu_hết trường_hợp dị_ứng thực_phẩm có liên_quan đến protein trong thực_phẩm như sữa bò trứng đậu_phộng động_vật có vỏ triệu_chứng của dị_ứng thực_phẩm khác nhau ở từng người từ nhẹ đến nghiêm_trọng nếu đe_dọa tính_mạng gọi là sốc phản_vệ tình_trạng dị_ứng có_thể nhẹ trong lần đầu nhưng đôi_khi nghiêm_trọng trong những lần sau triệu_chứng có xu_hướng kéo_dài vài phút đến vài giờ hoặc lâu hơn như sưng và ngứa môi miệng đau thắt_cổ_họng khàn giọng buồn_nôn_nôn tiêu_chảy nổi mề_đay phát_ban sưng ngứa da dưới đây là 8 loại dị_ứng thực_phẩm phổ_biến sữa bò khi bị dị_ứng sữa hệ_thống miễn_dịch sẽ phản_ứng thái_quá với protein trong sữa là casein và whey đây là dị_ứng thực_phẩm phổ_biến ở trẻ_em theo nghiên_cứu của viện dị_ứng thực_phẩm elliot và roslyn jaffe mỹ trẻ_em từ 5 tuổi trở lên thường sẽ hết dị_ứng sữa và có_thể dung_nạp protein sữa ở tuổi thiếu_niên các sản_phẩm khác chứa sữa cũng có_thể gây dị_ứng mọi người nên xem kỹ thành_phần trên nhãn thực_phẩm để tránh có phản_ứng khi tiêu_thụ những thành_phần mà người bị dị_ứng sữa nên tránh như casein sữa bơ kem sữa điaxetyl lactose váng sữa trứng dị_ứng trứng là do protein trong trứng được kích_hoạt khi tiêu_thụ bạn có_thể bị dị_ứng với lòng_trắng lòng_đỏ hoặc cả hai đây là loại dị_ứng thực_phẩm phổ_biến thứ hai ở trẻ_em thường xảy ra trước 2 tuổi và thường hết khi 5 tuổi trở lên trứng có_thể chứa trong các thực_phẩm khác người bị dị_ứng trứng nên đọc kỹ nhãn thành_phần trước khi dùng thực_phẩm protein trứng cũng có_thể có trong vaccine cúm và mmr sởi quai_bị và rubella nếu bạn bị dị_ứng trứng nên nói với bác_sĩ nhân_viên tiêm_chủng trước khi tiêm những vaccine này hạt cây một_số người có_thể dị_ứng với các loại hạt như hạt_dẻ cười óc chó hồ đào hạnh_nhân hạt phỉ nguy_cơ phản_ứng sốc phản_vệ đối_với các loại hạt cây cao hơn sữa trứng hoặc lúa_mì dị_ứng hạt cây có_thể xuất_hiện ở cả trẻ_em và người_lớn thường là một chứng dị_ứng kéo_dài suốt đời một_số trẻ có_thể hết dị_ứng hạt cây khi lên 6 tuổi hạt có_thể có trong các loại thực_phẩm người bị dị_ứng nên lưu_ý ngũ_cốc bánh_quy kẹo nước sốt thịt nguội đậu_phộng dị_ứng đậu_phộng thường nguy_hiểm vì tỷ_lệ sốc phản_vệ cao hơn dị_ứng sữa hay trứng protein trong đậu_phộng tương_tự như các loại hạt cây nếu bị dị_ứng đậu_phộng bạn có nhiều khả_năng bị dị_ứng hạt cây và ngược_lại bạn bị dị_ứng với đậu_phộng không có_nghĩa_là bạn sẽ bị dị_ứng với các loại đậu khác như đậu_nành đậu hà_lan đậu lăng theo đại_học dị_ứng hen và miễn_dịch học mỹ với nhiều người dị_ứng đậu_phộng kéo_dài suốt đời một lượng nhỏ protein đậu_phộng cũng có_thể gây ra phản_ứng người bị dị_ứng với thực_phẩm này nên đọc nhãn thành_phần cẩn_thận đậu_phộng có_thể được tìm thấy trong các thực_phẩm như tương_ớt bánh_mì ngũ_cốc bánh kem granola trứng cuộn salad kem đậu_nành cơ_thể có_thể phản_ứng với protein trong loại đậu này các phản_ứng dị_ứng thường nhẹ nhưng đôi_khi có_thể nghiêm_trọng nguy_hiểm tính_mạng tình_trạng này thường xảy ra ở trẻ_em và sẽ hết khi trẻ 10 tuổi những thhực phẩm và đồ uống có đậu_nành bạn nên lưu_ý như sữa công_thức cho trẻ sơ_sinh sữa đậu_nành súp miso đậu_hũ cá_ngừ đóng_hộp bơ đậu_phộng nước sốt mè giống như các chất gây dị_ứng khác người bị dị_ứng với mè vừng là do cơ_thể có phản_ứng miễn_dịch với các protein trong thực_phẩm này dị_ứng mè cũng phổ_biến ở cả trẻ_em và người_lớn trẻ_em thường khỏi dị_ứng mè khi lớn lên mè thường được sử_dụng để thêm hương_vị dưới dạng lớp phủ lên trên hoặc dầu ăn_người mẫn_cảm nên tránh các món ăn có sử_dụng mè như bánh_mì đồ nướng sốt nước_chấm kẹo bánh_quy sushi dầu mè một_số loại như cá_ngừ cá tuyết cá_bơn cá_hồi có_thể gây dị_ứng do cơ_thể phản_ứng với protein trong cá phản_ứng dị_ứng thường là do ăn cá nhưng một_số người có_thể có các triệu_chứng sau khi chạm vào cá hoặc hít phải hơi cá đông_lạnh cá đang nấu chín động_vật có vỏ dị_ứng với động_vật có vỏ tôm cua ốc thường có xu_hướng nghiêm_trọng phản_ứng có_thể xảy ra do ăn chạm vào hoặc hít phải hơi_nước khi nấu động_vật có vỏ dị_ứng thường phổ_biến ở người_lớn hơn và có_thể tồn_tại suốt đời sốc phản_vệ là dạng nghiêm_trọng nhất của dị_ứng tình_trạng này gây ra các triệu_chứng như khó thở hoặc thở khò_khè cổ_họng như bị nghẹn sưng môi lưỡi đỏ_bừng nổi mề_đay ngứa da buồn_nôn và nôn_đau dạ_dày tim đập nhanh huyết_áp_thấp mất ý_thức nếu có các dấu_hiệu trên sau khi tiêu_thụ thức_ăn hoặc tiếp_xúc với thực_phẩm người_bệnh cần được nhanh_chóng nhập_viện',\n 'một cđv có ảnh_hưởng trên mạng xã_hội trung quốc òa khóc tại sân vận_động khalifa khi thấy nhật thắng đức vì buồn cho bóng_đá nước_nhà goat người có hơn 200 000 lượt theo_dõi trên mạng xã_hội weibo hôm 23 11 đăng video anh khóc trước chiến_thắng gây sốc của đội_tuyển nhật bản trước đội_tuyển đức trong trận ra_quân tại world_cup 2022 ở sân vận_động khalifa thủ_đô doha của qatar đó là nước láng_giềng của chúng_ta thể_chất của chúng_ta tương_tự họ tại_sao họ có_thể thắng còn chúng_ta thì không goat vừa nói vừa khóc trong video nhật bản lội ngược dòng bằng hai bàn thắng ở 15 phút thi_đấu chính_thức cuối hiệp hai tạo nên chiến_thắng gây chấn_động trước đội_tuyển đức từng 4 lần vô_địch world_cup cổ_động_viên nhật bản có_mặt tại sân vận_động và ở trong nước đều vỡ òa ăn_mừng chiến_thắng này trong khi đó trung_quốc đã không lọt vào vòng chung_kết world_cup kể từ năm 2002 khi nhật bản và hàn_quốc là đồng chủ nhà một_số người dùng weibo nhanh_chóng chế_giễu goat vì đã khóc nhưng những người khác bày_tỏ sự ủng_hộ đừng chua_ngoa hay cười_cợt tại_sao bạn không đồng_ý với anh_chàng này nếu bạn ở đó và trải nghiệm bầu không_khí đó bạn cũng sẽ cảm_thấy như vậy một người bình_luận cảnh_tượng người hâm_mộ khóc thật buồn các cầu_thủ khác đang thi_đấu hết_mình trên sân chúng_ta chỉ có_thể xem trên tv và cổ_vũ cho các quốc_gia khác một người cho hay ý_kiến khác cho rằng người hâm_mộ bóng_đá quan_tâm vấn_đề này nhưng các cầu_thủ trung quốc thì không một_số người có cách tiếp_cận thẳng_thắn hơn khi khoảng_cách giữa lý_tưởng và thực_tế quá lớn mọi người không_thể không hỏi tại_sao sự khác_biệt lại lớn như vậy một tài_khoản weibo bình_luận điều đáng xấu_hổ hơn nữa là không_thể chọn ra 14 cầu_thủ trong số 1 4 tỷ người một người khác chỉ_trích anh khóc cái gì hãy nhìn kỹ hơn vào những gì chúng_ta có_thể làm một người nêu vâng chúng_ta có cùng vóc_dáng nhưng có chất_lượng như nhau không hãy lạc_quan hơn nước nào cũng có thế mạnh của mình với rất nhiều huy_chương vàng ở thế vận_hội thất_bại trong bóng_đá cũng chẳng có gì đáng buồn một_số ý_kiến tỏ ra lạc_quan hơn như trong kỳ world_cup tiếp_theo tôi hy_vọng đội_tuyển trung quốc có_thể tham_gia và trở_thành điểm sáng của châu á tiến lên nào trung_quốc',\n 'cách bài_tập thở bằng mũi bụng giúp tăng lượng oxy hít vào cải_thiện chức_năng hô_hấp giảm căng_thẳng lông mũi lọc bụi chất gây dị_ứng và phấn hoa ngăn chúng xâm_nhập vào phổi mũi còn làm ẩm không_khí hít vào không_khí sạch và ẩm giúp_việc hít thở dễ_dàng hơn trong quá_trình thở bằng mũi mũi của bạn tiết ra oxit nitric oxit nitric là chất làm giãn mạch giúp mở_rộng các mạch_máu cải_thiện lưu_thông oxy trong cơ_thể để giúp mũi nói_riêng và cơ_quan hô_hấp hoạt_động hiệu_quả hợn dưới đây là gợi_ý ba bài_tập đơn_giản mà bạn có_thể thực_hiện bài_tập thở lỗ mũi luân_phiên thở lỗ mũi luân_phiên nadishodhana là một bài_tập thở phổ_biến được sử_dụng trong yoga để thực_hiện bài_tập này bạn ngồi thẳng lưng và thả_lỏng vai đặt tay_trái của bạn lên đầu_gối trái bạn sử_dụng ngón tay phải để đóng lỗ mũi phải hít vào qua lỗ mũi trái sau đó dùng tay đóng lỗ mũi trái mở lỗ mũi phải và thở ra thực_hiện trong khoảng 5 phút bài_tập thở bằng bụng thở bằng bụng còn được gọi là thở bằng cơ_hoành mục_tiêu là hít thở đủ sâu làm tăng lượng oxy và giúp làm chậm nhịp thở và nhịp tim bài_tập này cũng có_thể giảm căng_thẳng để thực_hiện bài_tập này bạn ngồi thẳng lưng và thả_lỏng vai hoặc có_thể nằm_xuống giường ngậm_miệng lại đặt một tay lên bụng và một tay lên ngực bạn hít vào từ từ bằng mũi để_bụng phồng lên và đầy không_khí ngực giữ yên sau đó bạn mím môi và thở ra từ từ lặp_lại trong 5 đến 10 phút bài_tập hơi thở của lửa hơi thở của lửa là một bài_tập được sử_dụng trong yoga kundalini yoga thiên về nhận_thức kỹ_thuật này có_thể giúp cải_thiện chức_năng hô_hấp bằng cách sử_dụng các cơ hô_hấp và cơ_hoành tăng_cường sự tập_trung bạn ngồi thẳng lưng và thả_lỏng vai đặt tay lên bụng bạn cũng có_thể đặt tay lên đầu_gối lòng bàn_tay hướng lên trên hít sâu bằng mũi cảm_nhận không_khí di_chuyển xuống bụng và bụng mở ra bạn tiếp_tục thở ra thật mạnh bằng mũi trong khi co cơ bụng giữ độ dài hít vào và thở ra bằng nhau bạn thực_hiện các bước này và tăng_tốc_độ hít vào và thở ra lặp_lại trong 30 giây nếu bạn chưa quen với bài_tập thì nên bắt_đầu_từ từ bạn có_thể không nhận ra mình đang thở bằng miệng thay_vì bằng mũi nhất_là khi ngủ những người thở bằng miệng vào ban_đêm có_thể có các triệu_chứng như ngáy khô miệng hôi miệng khàn tiếng thức dậy mệt_mỏi và cáu_kỉnh mệt_mỏi mạn tính sương_mù não quầng thâm dưới mắt có nhiều nguyên_nhân khiến mũi bị nghẹt như nghẹt mũi do dị_ứng cảm lạnh hoặc nhiễm_trùng xoang amidan to lệch vách ngăn mũi có khối_u một_số người hình_thành có thở bằng miệng thay_vì mũi ngay cả khi hết tắc_nghẽn mũi một_số người bị ngưng thở khi ngủ có_thể có thói_quen há miệng khi ngủ để đáp_ứng nhu_cầu thở oxy căng_thẳng và lo_lắng khiến nhiều thở bằng miệng thay_vì mũi căng_thẳng kích_hoạt hệ_thống thần_kinh giao_cảm_dẫn đến thở nông nhanh và bất_thường do đó thực_hiện các bài_tập thở sẽ có_ích cho mũi nói_riêng và hệ hô_hấp nói_chung']"},"metadata":{}}]},{"cell_type":"code","source":"import pickle\npickle.dump(datanews, open('preprocess_datanews.pkl', 'wb'))","metadata":{"execution":{"iopub.status.busy":"2022-11-12T14:35:27.691052Z","iopub.execute_input":"2022-11-12T14:35:27.691561Z","iopub.status.idle":"2022-11-12T14:35:27.737890Z","shell.execute_reply.started":"2022-11-12T14:35:27.691519Z","shell.execute_reply":"2022-11-12T14:35:27.736981Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def truncatedvectors(data,n_components=300):\n  svd_ngram = TruncatedSVD(n_components=n_components, random_state=42)\n  svd_ngram.fit(data)\n  return svd_ngram.transform(data)","metadata":{"id":"Q_J0c8QEhlSd","execution":{"iopub.status.busy":"2022-11-03T15:15:58.276755Z","iopub.execute_input":"2022-11-03T15:15:58.277228Z","iopub.status.idle":"2022-11-03T15:15:58.289394Z","shell.execute_reply.started":"2022-11-03T15:15:58.277186Z","shell.execute_reply":"2022-11-03T15:15:58.288117Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def truncatedvectors(data, n_components=300):\n    svd_ngram = pickle.load(open(\"/kaggle/working/svd_ngram.pickle\", \"rb\"))\n    return svd_ngram.transform(data)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T14:30:15.576605Z","iopub.execute_input":"2022-12-13T14:30:15.577306Z","iopub.status.idle":"2022-12-13T14:30:15.582545Z","shell.execute_reply.started":"2022-12-13T14:30:15.577268Z","shell.execute_reply":"2022-12-13T14:30:15.581038Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"svd_ngram = TruncatedSVD(n_components=300, random_state=42)\nsvd_ngram.fit(X_data_tfidf_ngram)\npickle.dump(svd_ngram, open('svd_ngram.pickle', 'wb'))\nX_data_tfidf_ngram = svd_ngram.transform(X_data_tfidf_ngram)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T13:48:00.160105Z","iopub.execute_input":"2022-12-13T13:48:00.160606Z","iopub.status.idle":"2022-12-13T13:48:09.517237Z","shell.execute_reply.started":"2022-12-13T13:48:00.160572Z","shell.execute_reply":"2022-12-13T13:48:09.516218Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"TF-IDF","metadata":{"id":"1Abp-Ie4lqjc"}},{"cell_type":"code","source":"def tfidf(data):\n  tfidf_vect_ngram = TfidfVectorizer(analyzer='word', max_features=30000, ngram_range=(1, 2))\n  tfidf_vect_ngram.fit(data)\n  X_data_tfidf_ngram =  tfidf_vect_ngram.transform(data)\n  return truncatedvectors(X_data_tfidf_ngram)","metadata":{"id":"L3-Vj04-kRqZ","execution":{"iopub.status.busy":"2022-11-03T15:17:11.321071Z","iopub.execute_input":"2022-11-03T15:17:11.321426Z","iopub.status.idle":"2022-11-03T15:17:11.327507Z","shell.execute_reply.started":"2022-11-03T15:17:11.321396Z","shell.execute_reply":"2022-11-03T15:17:11.326297Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def tfidf(data):\n    tfidf_vect_ngram = pickle.load(open(\"/kaggle/working/tfidf.pickle\", \"rb\"))\n    X_data_tfidf_ngram = tfidf_vect_ngram.transform(data)\n    return truncatedvectors(X_data_tfidf_ngram)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T14:30:12.855353Z","iopub.execute_input":"2022-12-13T14:30:12.855730Z","iopub.status.idle":"2022-12-13T14:30:12.860709Z","shell.execute_reply.started":"2022-12-13T14:30:12.855698Z","shell.execute_reply":"2022-12-13T14:30:12.859785Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"import pickle\ntfidf_vect_ngram = TfidfVectorizer(analyzer='word', max_features=30000, ngram_range=(1, 2))\ntfidf_vect_ngram.fit(datanews)\npickle.dump(tfidf_vect_ngram, open('tfidf.pickle', 'wb'))\nX_data_tfidf_ngram =  tfidf_vect_ngram.transform(datanews)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T13:46:32.694009Z","iopub.execute_input":"2022-12-13T13:46:32.694383Z","iopub.status.idle":"2022-12-13T13:46:40.022534Z","shell.execute_reply.started":"2022-12-13T13:46:32.694353Z","shell.execute_reply":"2022-12-13T13:46:40.021571Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"X_data_tfidf = X_data_tfidf_ngram","metadata":{"execution":{"iopub.status.busy":"2022-12-13T13:49:05.331707Z","iopub.execute_input":"2022-12-13T13:49:05.332734Z","iopub.status.idle":"2022-12-13T13:49:05.337209Z","shell.execute_reply.started":"2022-12-13T13:49:05.332688Z","shell.execute_reply":"2022-12-13T13:49:05.336225Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"X_data_tfidf = tfidf(datanews)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T14:30:19.307541Z","iopub.execute_input":"2022-12-13T14:30:19.307935Z","iopub.status.idle":"2022-12-13T14:30:22.267906Z","shell.execute_reply.started":"2022-12-13T14:30:19.307896Z","shell.execute_reply":"2022-12-13T14:30:22.266930Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"X_data_tfidf[0].shape","metadata":{"execution":{"iopub.status.busy":"2022-12-13T14:30:38.818741Z","iopub.execute_input":"2022-12-13T14:30:38.819122Z","iopub.status.idle":"2022-12-13T14:30:38.825872Z","shell.execute_reply.started":"2022-12-13T14:30:38.819083Z","shell.execute_reply":"2022-12-13T14:30:38.824706Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"(300,)"},"metadata":{}}]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_data_tfidf, labelnews, test_size=0.2, random_state=42, stratify=labelnews)","metadata":{"id":"EEsMFGnxUO2C","execution":{"iopub.status.busy":"2022-12-13T13:49:18.161474Z","iopub.execute_input":"2022-12-13T13:49:18.161864Z","iopub.status.idle":"2022-12-13T13:49:18.174245Z","shell.execute_reply.started":"2022-12-13T13:49:18.161824Z","shell.execute_reply":"2022-12-13T13:49:18.173043Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"Word2Vec","metadata":{"id":"mgqYlZ2bls2M"}},{"cell_type":"code","source":"# pip install gensim==3.8.3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from gensim.models import Word2Vec,KeyedVectors \n# import os\n# word2vec_model_path =\"/kaggle/input/word2vecvn-trained-model/wiki.vi.model.bin\"\n# model = KeyedVectors.load_word2vec_format(word2vec_model_path,binary=True, unicode_errors='ignore')\n# vocab = model.wv.vocab\n# wv = model.wv","metadata":{"id":"fWHlWQTdlvMu","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def get_word2vec_data(X):\n#     word2vec_data = []\n#     for x in X:\n#         sentence = []\n#         for word in x.split(\" \"):\n#             if word in vocab:\n#               sentence=sentence+wv[word].ravel().tolist()\n#         word2vec_data.append(sentence)\n#     return word2vec_data\n    \n# def change_to_word2vec(data):\n#   data2vec=get_word2vec_data(data)\n#   lengthOfdata=[len(data2vec[i]) for i,n in enumerate(data2vec)]\n#   for i,n in enumerate(data):\n#     if(len(data2vec[i])<max(lengthOfdata)):\n#       for j in range(1,(max(lengthOfdata)-len(data2vec[i]))+1):\n#         data2vec[i].append(0)\n#   return truncatedvectors(np.array(data2vec))","metadata":{"id":"uz4vnCOtmlVF","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# len(get_word2vec_data(datanews)[0])","metadata":{"id":"8FpnhPjvL7F0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train_w2v=change_to_word2vec(X_train)\n# X_test_w2v=change_to_word2vec(X_test)","metadata":{"id":"8XsqQC6krlZa","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SVM","metadata":{"id":"O7aAXY7aucW3"}},{"cell_type":"code","source":"clf=svm.SVC(kernel='linear',C=1000)\nclf.fit(X_train, y_train)\nval_predictions = clf.predict(X_test)\nprint(classification_report(y_test, val_predictions))","metadata":{"id":"cXMLhbdeumTN","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ea5a2d32-d64b-41c6-d38b-2b622c7224f1","execution":{"iopub.status.busy":"2022-11-03T16:16:31.324155Z","iopub.execute_input":"2022-11-03T16:16:31.324521Z","iopub.status.idle":"2022-11-03T16:16:31.580812Z","shell.execute_reply.started":"2022-11-03T16:16:31.324488Z","shell.execute_reply":"2022-11-03T16:16:31.579790Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n    Doi_song       0.75      0.79      0.77        57\n     Du_lich       0.97      0.95      0.96        61\n    Giai_tri       0.95      0.93      0.94        59\n    Giao_duc       0.97      0.98      0.97        57\n    Khoa_hoc       0.98      1.00      0.99        51\n   Phap_luat       0.92      0.97      0.95        63\n    Suc_khoe       0.87      0.78      0.82        60\n    The_thao       1.00      1.00      1.00        63\n\n    accuracy                           0.93       471\n   macro avg       0.93      0.93      0.93       471\nweighted avg       0.93      0.93      0.93       471\n\n","output_type":"stream"}]},{"cell_type":"code","source":"pickle.dump(clf, open('Vi_svm_textclassifier.pkl', 'wb'))","metadata":{"execution":{"iopub.status.busy":"2022-11-03T16:19:36.792539Z","iopub.execute_input":"2022-11-03T16:19:36.793014Z","iopub.status.idle":"2022-11-03T16:19:36.804306Z","shell.execute_reply.started":"2022-11-03T16:19:36.792976Z","shell.execute_reply":"2022-11-03T16:19:36.803149Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"LSTM","metadata":{"id":"t2dtBe9A6B5B"}},{"cell_type":"code","source":"#learning_rate: [1e-5,5e-5,1e-4,5e-4,1e-3,5e-3]\nopt = Adam(learning_rate=0.001)\ndef create_lstm_model():\n    input_layer = Input(shape=(300,))\n    layer = Reshape((10, 30,))(input_layer)\n    layer = LSTM(128, activation='relu',dropout=0.5, recurrent_dropout=0.5, return_sequences=True)(layer)\n    layer = LSTM(128)(layer)\n    layer = Dense(64, activation='relu')(layer)\n    layer = Dense(32, activation='relu')(layer)\n    output_layer = Dense(10, activation='softmax')(layer)\n    classifier = Model(input_layer, output_layer)\n    classifier.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n    return classifier","metadata":{"id":"o3BwHSkUvHrS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"32d1db06-8014-4340-db70-c41f82020460","execution":{"iopub.status.busy":"2023-02-12T06:12:05.473434Z","iopub.execute_input":"2023-02-12T06:12:05.473866Z","iopub.status.idle":"2023-02-12T06:12:05.497009Z","shell.execute_reply.started":"2023-02-12T06:12:05.473828Z","shell.execute_reply":"2023-02-12T06:12:05.495845Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nearlyStopping = EarlyStopping(monitor='loss', patience=10, verbose=0, mode='min')\nmcp_save = ModelCheckpoint('Vi_lstm_textclassifier.h5', save_best_only=True, monitor='val_loss', mode='min')\nreduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-3, mode='min')","metadata":{"execution":{"iopub.status.busy":"2023-02-12T06:12:05.844489Z","iopub.execute_input":"2023-02-12T06:12:05.844915Z","iopub.status.idle":"2023-02-12T06:12:05.853269Z","shell.execute_reply.started":"2023-02-12T06:12:05.844876Z","shell.execute_reply":"2023-02-12T06:12:05.852258Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"pd.get_dummies(y_train)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T13:51:02.955458Z","iopub.execute_input":"2022-12-13T13:51:02.956151Z","iopub.status.idle":"2022-12-13T13:51:02.974092Z","shell.execute_reply.started":"2022-12-13T13:51:02.956102Z","shell.execute_reply":"2022-12-13T13:51:02.973264Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"      Other  du-lich_diem-den  giai-tri_gioi-sao  giao-duc_tin-tuc  \\\n4102      0                 0                  0                 0   \n2741      1                 0                  0                 0   \n4600      1                 0                  0                 0   \n3641      0                 0                  0                 0   \n2035      1                 0                  0                 0   \n...     ...               ...                ...               ...   \n737       0                 0                  1                 0   \n4303      1                 0                  0                 0   \n4089      0                 0                  0                 0   \n403       0                 0                  0                 0   \n1618      0                 0                  0                 0   \n\n      khoa-hoc_tin-tuc  suc-khoe_cac-benh  suc-khoe_tin-tuc  the-thao_bong-da  \\\n4102                 0                  1                 0                 0   \n2741                 0                  0                 0                 0   \n4600                 0                  0                 0                 0   \n3641                 0                  0                 1                 0   \n2035                 0                  0                 0                 0   \n...                ...                ...               ...               ...   \n737                  0                  0                 0                 0   \n4303                 0                  0                 0                 0   \n4089                 0                  1                 0                 0   \n403                  1                  0                 0                 0   \n1618                 0                  0                 0                 1   \n\n      the-thao_cac-mon-khac  the-thao_world-cup-2022  \n4102                      0                        0  \n2741                      0                        0  \n4600                      0                        0  \n3641                      0                        0  \n2035                      0                        0  \n...                     ...                      ...  \n737                       0                        0  \n4303                      0                        0  \n4089                      0                        0  \n403                       0                        0  \n1618                      0                        0  \n\n[2378 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Other</th>\n      <th>du-lich_diem-den</th>\n      <th>giai-tri_gioi-sao</th>\n      <th>giao-duc_tin-tuc</th>\n      <th>khoa-hoc_tin-tuc</th>\n      <th>suc-khoe_cac-benh</th>\n      <th>suc-khoe_tin-tuc</th>\n      <th>the-thao_bong-da</th>\n      <th>the-thao_cac-mon-khac</th>\n      <th>the-thao_world-cup-2022</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4102</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2741</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4600</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3641</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2035</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>737</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4303</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4089</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>403</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1618</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2378 rows × 10 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# y_train_dummies = pd.get_dummies(y_train).values\nclassifier = create_lstm_model()\nprint(classifier.summary())","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d0u5O7iB4VOA","outputId":"300766db-3fee-4a19-eb56-da44206e85a1","execution":{"iopub.status.busy":"2023-02-12T06:12:14.796009Z","iopub.execute_input":"2023-02-12T06:12:14.796479Z","iopub.status.idle":"2023-02-12T06:12:15.880311Z","shell.execute_reply.started":"2023-02-12T06:12:14.796436Z","shell.execute_reply":"2023-02-12T06:12:15.879093Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"2023-02-12 06:12:14.858119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-12 06:12:14.859302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-12 06:12:14.860236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-12 06:12:14.861465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-12 06:12:14.862363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-12 06:12:14.863260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-12 06:12:14.864221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-12 06:12:14.865103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-12 06:12:14.865889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 300)]             0         \n_________________________________________________________________\nreshape (Reshape)            (None, 10, 30)            0         \n_________________________________________________________________\nlstm (LSTM)                  (None, 10, 128)           81408     \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 128)               131584    \n_________________________________________________________________\ndense (Dense)                (None, 64)                8256      \n_________________________________________________________________\ndense_1 (Dense)              (None, 32)                2080      \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                330       \n=================================================================\nTotal params: 223,658\nTrainable params: 223,658\nNon-trainable params: 0\n_________________________________________________________________\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"classifier.fit(X_train, y_train_dummies, validation_split=0.1, epochs=400, batch_size=32, callbacks=mcp_save)\n# classifier.fit(X_train, y_train_dummies, validation_split=0.1, epochs=400, batch_size=32, callbacks=[earlyStopping, mcp_save, reduce_lr_loss])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WeeICZIodhVH","outputId":"4924466e-7457-475b-f359-76d36ff682c7","execution":{"iopub.status.busy":"2022-12-13T13:51:05.339368Z","iopub.execute_input":"2022-12-13T13:51:05.340412Z","iopub.status.idle":"2022-12-13T14:11:14.786685Z","shell.execute_reply.started":"2022-12-13T13:51:05.340373Z","shell.execute_reply":"2022-12-13T14:11:14.785754Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Epoch 1/400\n","output_type":"stream"},{"name":"stderr","text":"2022-12-13 13:51:10.687289: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"67/67 [==============================] - 9s 49ms/step - loss: 2.2844 - accuracy: 0.1668 - val_loss: 2.2688 - val_accuracy: 0.1261\nEpoch 2/400\n67/67 [==============================] - 3s 43ms/step - loss: 2.1661 - accuracy: 0.2051 - val_loss: 1.9454 - val_accuracy: 0.2185\nEpoch 3/400\n67/67 [==============================] - 3s 43ms/step - loss: 2.0048 - accuracy: 0.2051 - val_loss: 1.7741 - val_accuracy: 0.2269\nEpoch 4/400\n67/67 [==============================] - 3s 47ms/step - loss: 1.8869 - accuracy: 0.2435 - val_loss: 1.6153 - val_accuracy: 0.2311\nEpoch 5/400\n67/67 [==============================] - 3s 42ms/step - loss: 1.7646 - accuracy: 0.2682 - val_loss: 1.4742 - val_accuracy: 0.3655\nEpoch 6/400\n67/67 [==============================] - 3s 43ms/step - loss: 1.6865 - accuracy: 0.3005 - val_loss: 1.3121 - val_accuracy: 0.3866\nEpoch 7/400\n67/67 [==============================] - 3s 47ms/step - loss: 1.5535 - accuracy: 0.3346 - val_loss: 1.1708 - val_accuracy: 0.4244\nEpoch 8/400\n67/67 [==============================] - 3s 43ms/step - loss: 1.4689 - accuracy: 0.3687 - val_loss: 1.1679 - val_accuracy: 0.4412\nEpoch 9/400\n67/67 [==============================] - 4s 53ms/step - loss: 1.3993 - accuracy: 0.3766 - val_loss: 1.0743 - val_accuracy: 0.4874\nEpoch 10/400\n67/67 [==============================] - 3s 42ms/step - loss: 1.3292 - accuracy: 0.4168 - val_loss: 1.0083 - val_accuracy: 0.5546\nEpoch 11/400\n67/67 [==============================] - 3s 47ms/step - loss: 1.3050 - accuracy: 0.4678 - val_loss: 0.9530 - val_accuracy: 0.5546\nEpoch 12/400\n67/67 [==============================] - 3s 42ms/step - loss: 1.2278 - accuracy: 0.4822 - val_loss: 0.9050 - val_accuracy: 0.6261\nEpoch 13/400\n67/67 [==============================] - 3s 41ms/step - loss: 1.2435 - accuracy: 0.4902 - val_loss: 0.9241 - val_accuracy: 0.5588\nEpoch 14/400\n67/67 [==============================] - 3s 43ms/step - loss: 1.1345 - accuracy: 0.5491 - val_loss: 0.8334 - val_accuracy: 0.6723\nEpoch 15/400\n67/67 [==============================] - 3s 49ms/step - loss: 1.1379 - accuracy: 0.5430 - val_loss: 0.9014 - val_accuracy: 0.6765\nEpoch 16/400\n67/67 [==============================] - 3s 42ms/step - loss: 1.0804 - accuracy: 0.5743 - val_loss: 0.7303 - val_accuracy: 0.7269\nEpoch 17/400\n67/67 [==============================] - 3s 42ms/step - loss: 1.0658 - accuracy: 0.5916 - val_loss: 0.7529 - val_accuracy: 0.6849\nEpoch 18/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.9985 - accuracy: 0.6299 - val_loss: 0.6906 - val_accuracy: 0.7941\nEpoch 19/400\n67/67 [==============================] - 3s 43ms/step - loss: 1.0260 - accuracy: 0.6047 - val_loss: 0.6902 - val_accuracy: 0.7605\nEpoch 20/400\n67/67 [==============================] - 4s 54ms/step - loss: 0.9739 - accuracy: 0.6224 - val_loss: 0.6688 - val_accuracy: 0.7899\nEpoch 21/400\n67/67 [==============================] - 3s 45ms/step - loss: 0.9177 - accuracy: 0.6537 - val_loss: 0.5945 - val_accuracy: 0.7731\nEpoch 22/400\n67/67 [==============================] - 3s 50ms/step - loss: 0.9294 - accuracy: 0.6612 - val_loss: 0.6166 - val_accuracy: 0.7689\nEpoch 23/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.8668 - accuracy: 0.6827 - val_loss: 0.5964 - val_accuracy: 0.8109\nEpoch 24/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.8703 - accuracy: 0.6748 - val_loss: 0.6217 - val_accuracy: 0.7605\nEpoch 25/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.8697 - accuracy: 0.6813 - val_loss: 0.5823 - val_accuracy: 0.8067\nEpoch 26/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.8754 - accuracy: 0.6696 - val_loss: 0.6422 - val_accuracy: 0.7563\nEpoch 27/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.7941 - accuracy: 0.7150 - val_loss: 0.5396 - val_accuracy: 0.8235\nEpoch 28/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.8518 - accuracy: 0.6897 - val_loss: 0.5790 - val_accuracy: 0.7899\nEpoch 29/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.8093 - accuracy: 0.7042 - val_loss: 0.5610 - val_accuracy: 0.8277\nEpoch 30/400\n67/67 [==============================] - 3s 51ms/step - loss: 0.8128 - accuracy: 0.7093 - val_loss: 0.5615 - val_accuracy: 0.7899\nEpoch 31/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.7432 - accuracy: 0.7364 - val_loss: 0.5688 - val_accuracy: 0.7983\nEpoch 32/400\n67/67 [==============================] - 3s 45ms/step - loss: 0.7667 - accuracy: 0.7196 - val_loss: 0.5342 - val_accuracy: 0.7983\nEpoch 33/400\n67/67 [==============================] - 3s 45ms/step - loss: 0.7606 - accuracy: 0.7285 - val_loss: 0.5691 - val_accuracy: 0.8025\nEpoch 34/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.7233 - accuracy: 0.7393 - val_loss: 0.5496 - val_accuracy: 0.8151\nEpoch 35/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.7817 - accuracy: 0.7234 - val_loss: 0.5165 - val_accuracy: 0.8235\nEpoch 36/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.7406 - accuracy: 0.7355 - val_loss: 0.5590 - val_accuracy: 0.8067\nEpoch 37/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.7177 - accuracy: 0.7472 - val_loss: 0.5140 - val_accuracy: 0.8151\nEpoch 38/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.7173 - accuracy: 0.7393 - val_loss: 0.5624 - val_accuracy: 0.8067\nEpoch 39/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.7076 - accuracy: 0.7430 - val_loss: 0.5172 - val_accuracy: 0.8151\nEpoch 40/400\n67/67 [==============================] - 4s 56ms/step - loss: 0.7152 - accuracy: 0.7463 - val_loss: 0.5147 - val_accuracy: 0.8193\nEpoch 41/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.6822 - accuracy: 0.7570 - val_loss: 0.4957 - val_accuracy: 0.8361\nEpoch 42/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.6906 - accuracy: 0.7500 - val_loss: 0.5119 - val_accuracy: 0.8319\nEpoch 43/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.6850 - accuracy: 0.7509 - val_loss: 0.4774 - val_accuracy: 0.8277\nEpoch 44/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.7302 - accuracy: 0.7439 - val_loss: 0.5084 - val_accuracy: 0.7983\nEpoch 45/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.6743 - accuracy: 0.7500 - val_loss: 0.4952 - val_accuracy: 0.8361\nEpoch 46/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.6969 - accuracy: 0.7495 - val_loss: 0.4926 - val_accuracy: 0.8361\nEpoch 47/400\n67/67 [==============================] - 3s 46ms/step - loss: 0.6587 - accuracy: 0.7650 - val_loss: 0.4914 - val_accuracy: 0.8361\nEpoch 48/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.6578 - accuracy: 0.7668 - val_loss: 0.4749 - val_accuracy: 0.8277\nEpoch 49/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.6450 - accuracy: 0.7771 - val_loss: 0.4652 - val_accuracy: 0.8529\nEpoch 50/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.6363 - accuracy: 0.7743 - val_loss: 0.4816 - val_accuracy: 0.8235\nEpoch 51/400\n67/67 [==============================] - 4s 56ms/step - loss: 0.6631 - accuracy: 0.7589 - val_loss: 0.4533 - val_accuracy: 0.8487\nEpoch 52/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.6388 - accuracy: 0.7715 - val_loss: 0.4617 - val_accuracy: 0.8319\nEpoch 53/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.6125 - accuracy: 0.7855 - val_loss: 0.4709 - val_accuracy: 0.8445\nEpoch 54/400\n67/67 [==============================] - 3s 46ms/step - loss: 0.6335 - accuracy: 0.7729 - val_loss: 0.4862 - val_accuracy: 0.8277\nEpoch 55/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.6115 - accuracy: 0.7748 - val_loss: 0.4793 - val_accuracy: 0.8235\nEpoch 56/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.5977 - accuracy: 0.7790 - val_loss: 0.4803 - val_accuracy: 0.8235\nEpoch 57/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.6199 - accuracy: 0.7864 - val_loss: 0.4832 - val_accuracy: 0.8193\nEpoch 58/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.6453 - accuracy: 0.7687 - val_loss: 0.4755 - val_accuracy: 0.8487\nEpoch 59/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.6051 - accuracy: 0.7869 - val_loss: 0.4458 - val_accuracy: 0.8487\nEpoch 60/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.5796 - accuracy: 0.7963 - val_loss: 0.4939 - val_accuracy: 0.7941\nEpoch 61/400\n67/67 [==============================] - 3s 51ms/step - loss: 0.6103 - accuracy: 0.7893 - val_loss: 0.4637 - val_accuracy: 0.8445\nEpoch 62/400\n67/67 [==============================] - 3s 49ms/step - loss: 0.6073 - accuracy: 0.7846 - val_loss: 0.5180 - val_accuracy: 0.8067\nEpoch 63/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.6049 - accuracy: 0.7864 - val_loss: 0.4469 - val_accuracy: 0.8487\nEpoch 64/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.5777 - accuracy: 0.7963 - val_loss: 0.4243 - val_accuracy: 0.8613\nEpoch 65/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.5637 - accuracy: 0.8107 - val_loss: 0.4997 - val_accuracy: 0.8193\nEpoch 66/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.5841 - accuracy: 0.7935 - val_loss: 0.4532 - val_accuracy: 0.8529\nEpoch 67/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.5628 - accuracy: 0.8107 - val_loss: 0.4336 - val_accuracy: 0.8697\nEpoch 68/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.5903 - accuracy: 0.7902 - val_loss: 0.4537 - val_accuracy: 0.8403\nEpoch 69/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.6219 - accuracy: 0.7813 - val_loss: 0.4744 - val_accuracy: 0.8487\nEpoch 70/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.5654 - accuracy: 0.8056 - val_loss: 0.4303 - val_accuracy: 0.8655\nEpoch 71/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.5558 - accuracy: 0.7925 - val_loss: 0.4381 - val_accuracy: 0.8655\nEpoch 72/400\n67/67 [==============================] - 3s 52ms/step - loss: 0.5594 - accuracy: 0.8150 - val_loss: 0.4655 - val_accuracy: 0.8445\nEpoch 73/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.5480 - accuracy: 0.8047 - val_loss: 0.4235 - val_accuracy: 0.8655\nEpoch 74/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.5433 - accuracy: 0.8154 - val_loss: 0.4765 - val_accuracy: 0.8403\nEpoch 75/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.5543 - accuracy: 0.7995 - val_loss: 0.4431 - val_accuracy: 0.8403\nEpoch 76/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.5586 - accuracy: 0.8023 - val_loss: 0.4742 - val_accuracy: 0.8403\nEpoch 77/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.5333 - accuracy: 0.8168 - val_loss: 0.4494 - val_accuracy: 0.8361\nEpoch 78/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.5427 - accuracy: 0.8196 - val_loss: 0.4340 - val_accuracy: 0.8529\nEpoch 79/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.5170 - accuracy: 0.8215 - val_loss: 0.4302 - val_accuracy: 0.8782\nEpoch 80/400\n67/67 [==============================] - 3s 49ms/step - loss: 0.5293 - accuracy: 0.8150 - val_loss: 0.4307 - val_accuracy: 0.8403\nEpoch 81/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.5369 - accuracy: 0.8075 - val_loss: 0.4458 - val_accuracy: 0.8445\nEpoch 82/400\n67/67 [==============================] - 4s 54ms/step - loss: 0.5154 - accuracy: 0.8206 - val_loss: 0.4749 - val_accuracy: 0.8487\nEpoch 83/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.5464 - accuracy: 0.7995 - val_loss: 0.4320 - val_accuracy: 0.8613\nEpoch 84/400\n67/67 [==============================] - 3s 46ms/step - loss: 0.5268 - accuracy: 0.8145 - val_loss: 0.4438 - val_accuracy: 0.8571\nEpoch 85/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.5319 - accuracy: 0.8140 - val_loss: 0.4316 - val_accuracy: 0.8571\nEpoch 86/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.5364 - accuracy: 0.8028 - val_loss: 0.4469 - val_accuracy: 0.8571\nEpoch 87/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.5188 - accuracy: 0.8150 - val_loss: 0.4374 - val_accuracy: 0.8487\nEpoch 88/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.4828 - accuracy: 0.8336 - val_loss: 0.4818 - val_accuracy: 0.8361\nEpoch 89/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.5306 - accuracy: 0.8061 - val_loss: 0.4589 - val_accuracy: 0.8361\nEpoch 90/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.5038 - accuracy: 0.8215 - val_loss: 0.4500 - val_accuracy: 0.8529\nEpoch 91/400\n67/67 [==============================] - 3s 49ms/step - loss: 0.5072 - accuracy: 0.8224 - val_loss: 0.4756 - val_accuracy: 0.8487\nEpoch 92/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.5255 - accuracy: 0.8266 - val_loss: 0.4224 - val_accuracy: 0.8697\nEpoch 93/400\n67/67 [==============================] - 4s 52ms/step - loss: 0.5103 - accuracy: 0.8285 - val_loss: 0.4465 - val_accuracy: 0.8613\nEpoch 94/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.5169 - accuracy: 0.8168 - val_loss: 0.4391 - val_accuracy: 0.8403\nEpoch 95/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.5128 - accuracy: 0.8224 - val_loss: 0.4843 - val_accuracy: 0.8277\nEpoch 96/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.4982 - accuracy: 0.8318 - val_loss: 0.4360 - val_accuracy: 0.8487\nEpoch 97/400\n67/67 [==============================] - 3s 41ms/step - loss: 0.4923 - accuracy: 0.8299 - val_loss: 0.4240 - val_accuracy: 0.8613\nEpoch 98/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.4820 - accuracy: 0.8304 - val_loss: 0.4640 - val_accuracy: 0.8487\nEpoch 99/400\n67/67 [==============================] - 3s 41ms/step - loss: 0.5149 - accuracy: 0.8178 - val_loss: 0.4428 - val_accuracy: 0.8361\nEpoch 100/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.4720 - accuracy: 0.8322 - val_loss: 0.4155 - val_accuracy: 0.8613\nEpoch 101/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.4873 - accuracy: 0.8285 - val_loss: 0.4306 - val_accuracy: 0.8445\nEpoch 102/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.4938 - accuracy: 0.8248 - val_loss: 0.4249 - val_accuracy: 0.8571\nEpoch 103/400\n67/67 [==============================] - 3s 52ms/step - loss: 0.4791 - accuracy: 0.8313 - val_loss: 0.4820 - val_accuracy: 0.8445\nEpoch 104/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.4960 - accuracy: 0.8257 - val_loss: 0.4346 - val_accuracy: 0.8655\nEpoch 105/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.4765 - accuracy: 0.8248 - val_loss: 0.4700 - val_accuracy: 0.8571\nEpoch 106/400\n67/67 [==============================] - 3s 46ms/step - loss: 0.4496 - accuracy: 0.8346 - val_loss: 0.4448 - val_accuracy: 0.8571\nEpoch 107/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.5057 - accuracy: 0.8252 - val_loss: 0.4510 - val_accuracy: 0.8529\nEpoch 108/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.4899 - accuracy: 0.8215 - val_loss: 0.4338 - val_accuracy: 0.8697\nEpoch 109/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.4756 - accuracy: 0.8402 - val_loss: 0.4270 - val_accuracy: 0.8571\nEpoch 110/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.4577 - accuracy: 0.8439 - val_loss: 0.4192 - val_accuracy: 0.8782\nEpoch 111/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.4701 - accuracy: 0.8379 - val_loss: 0.4397 - val_accuracy: 0.8571\nEpoch 112/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.4928 - accuracy: 0.8285 - val_loss: 0.4461 - val_accuracy: 0.8319\nEpoch 113/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.4625 - accuracy: 0.8393 - val_loss: 0.4516 - val_accuracy: 0.8571\nEpoch 114/400\n67/67 [==============================] - 4s 54ms/step - loss: 0.4568 - accuracy: 0.8350 - val_loss: 0.4348 - val_accuracy: 0.8529\nEpoch 115/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.4874 - accuracy: 0.8280 - val_loss: 0.4965 - val_accuracy: 0.8277\nEpoch 116/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.4857 - accuracy: 0.8313 - val_loss: 0.4456 - val_accuracy: 0.8571\nEpoch 117/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.4763 - accuracy: 0.8369 - val_loss: 0.4267 - val_accuracy: 0.8655\nEpoch 118/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.4705 - accuracy: 0.8379 - val_loss: 0.4850 - val_accuracy: 0.8445\nEpoch 119/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.4440 - accuracy: 0.8421 - val_loss: 0.4307 - val_accuracy: 0.8445\nEpoch 120/400\n67/67 [==============================] - 3s 49ms/step - loss: 0.4846 - accuracy: 0.8308 - val_loss: 0.4259 - val_accuracy: 0.8655\nEpoch 121/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.4645 - accuracy: 0.8402 - val_loss: 0.4241 - val_accuracy: 0.8655\nEpoch 122/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.4710 - accuracy: 0.8346 - val_loss: 0.4585 - val_accuracy: 0.8487\nEpoch 123/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.4394 - accuracy: 0.8463 - val_loss: 0.4385 - val_accuracy: 0.8529\nEpoch 124/400\n67/67 [==============================] - 4s 57ms/step - loss: 0.4742 - accuracy: 0.8341 - val_loss: 0.4122 - val_accuracy: 0.8697\nEpoch 125/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.4788 - accuracy: 0.8276 - val_loss: 0.4056 - val_accuracy: 0.8571\nEpoch 126/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.4568 - accuracy: 0.8308 - val_loss: 0.4655 - val_accuracy: 0.8529\nEpoch 127/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.4524 - accuracy: 0.8294 - val_loss: 0.4210 - val_accuracy: 0.8571\nEpoch 128/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.4436 - accuracy: 0.8463 - val_loss: 0.4204 - val_accuracy: 0.8697\nEpoch 129/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.4675 - accuracy: 0.8364 - val_loss: 0.4687 - val_accuracy: 0.8487\nEpoch 130/400\n67/67 [==============================] - 3s 41ms/step - loss: 0.4394 - accuracy: 0.8425 - val_loss: 0.4288 - val_accuracy: 0.8571\nEpoch 131/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.4391 - accuracy: 0.8495 - val_loss: 0.4211 - val_accuracy: 0.8487\nEpoch 132/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.4635 - accuracy: 0.8416 - val_loss: 0.4221 - val_accuracy: 0.8571\nEpoch 133/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.4580 - accuracy: 0.8407 - val_loss: 0.4271 - val_accuracy: 0.8487\nEpoch 134/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.4409 - accuracy: 0.8393 - val_loss: 0.3999 - val_accuracy: 0.8571\nEpoch 135/400\n67/67 [==============================] - 4s 58ms/step - loss: 0.4237 - accuracy: 0.8575 - val_loss: 0.4358 - val_accuracy: 0.8739\nEpoch 136/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.4572 - accuracy: 0.8374 - val_loss: 0.4189 - val_accuracy: 0.8655\nEpoch 137/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.4464 - accuracy: 0.8444 - val_loss: 0.4284 - val_accuracy: 0.8529\nEpoch 138/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.4533 - accuracy: 0.8421 - val_loss: 0.4114 - val_accuracy: 0.8613\nEpoch 139/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.4269 - accuracy: 0.8500 - val_loss: 0.4503 - val_accuracy: 0.8571\nEpoch 140/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.4558 - accuracy: 0.8477 - val_loss: 0.4081 - val_accuracy: 0.8697\nEpoch 141/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.4534 - accuracy: 0.8491 - val_loss: 0.4335 - val_accuracy: 0.8487\nEpoch 142/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.4013 - accuracy: 0.8509 - val_loss: 0.4919 - val_accuracy: 0.8487\nEpoch 143/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.4570 - accuracy: 0.8383 - val_loss: 0.4520 - val_accuracy: 0.8319\nEpoch 144/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.4389 - accuracy: 0.8364 - val_loss: 0.4305 - val_accuracy: 0.8487\nEpoch 145/400\n67/67 [==============================] - 3s 52ms/step - loss: 0.4565 - accuracy: 0.8435 - val_loss: 0.4315 - val_accuracy: 0.8613\nEpoch 146/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.4279 - accuracy: 0.8514 - val_loss: 0.4433 - val_accuracy: 0.8613\nEpoch 147/400\n67/67 [==============================] - 3s 41ms/step - loss: 0.4274 - accuracy: 0.8495 - val_loss: 0.4574 - val_accuracy: 0.8613\nEpoch 148/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.4138 - accuracy: 0.8486 - val_loss: 0.4209 - val_accuracy: 0.8487\nEpoch 149/400\n67/67 [==============================] - 3s 46ms/step - loss: 0.4395 - accuracy: 0.8495 - val_loss: 0.4332 - val_accuracy: 0.8445\nEpoch 150/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.4191 - accuracy: 0.8477 - val_loss: 0.4107 - val_accuracy: 0.8613\nEpoch 151/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.4385 - accuracy: 0.8458 - val_loss: 0.4379 - val_accuracy: 0.8571\nEpoch 152/400\n67/67 [==============================] - 3s 41ms/step - loss: 0.4293 - accuracy: 0.8509 - val_loss: 0.4571 - val_accuracy: 0.8403\nEpoch 153/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.4214 - accuracy: 0.8477 - val_loss: 0.4321 - val_accuracy: 0.8487\nEpoch 154/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.4118 - accuracy: 0.8565 - val_loss: 0.4296 - val_accuracy: 0.8487\nEpoch 155/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3928 - accuracy: 0.8565 - val_loss: 0.4362 - val_accuracy: 0.8613\nEpoch 156/400\n67/67 [==============================] - 3s 51ms/step - loss: 0.4063 - accuracy: 0.8612 - val_loss: 0.4283 - val_accuracy: 0.8529\nEpoch 157/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.3924 - accuracy: 0.8636 - val_loss: 0.4147 - val_accuracy: 0.8571\nEpoch 158/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.4099 - accuracy: 0.8514 - val_loss: 0.4543 - val_accuracy: 0.8403\nEpoch 159/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.4114 - accuracy: 0.8491 - val_loss: 0.4542 - val_accuracy: 0.8487\nEpoch 160/400\n67/67 [==============================] - 3s 46ms/step - loss: 0.4164 - accuracy: 0.8528 - val_loss: 0.4218 - val_accuracy: 0.8529\nEpoch 161/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.4152 - accuracy: 0.8607 - val_loss: 0.4263 - val_accuracy: 0.8403\nEpoch 162/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.4088 - accuracy: 0.8491 - val_loss: 0.4829 - val_accuracy: 0.8403\nEpoch 163/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.4185 - accuracy: 0.8486 - val_loss: 0.3923 - val_accuracy: 0.8739\nEpoch 164/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.3971 - accuracy: 0.8617 - val_loss: 0.4158 - val_accuracy: 0.8571\nEpoch 165/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3954 - accuracy: 0.8650 - val_loss: 0.3950 - val_accuracy: 0.8613\nEpoch 166/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.4001 - accuracy: 0.8542 - val_loss: 0.3901 - val_accuracy: 0.8529\nEpoch 167/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.4175 - accuracy: 0.8509 - val_loss: 0.4342 - val_accuracy: 0.8571\nEpoch 168/400\n67/67 [==============================] - 3s 49ms/step - loss: 0.4251 - accuracy: 0.8486 - val_loss: 0.4545 - val_accuracy: 0.8529\nEpoch 169/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.4014 - accuracy: 0.8570 - val_loss: 0.4523 - val_accuracy: 0.8445\nEpoch 170/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.4233 - accuracy: 0.8467 - val_loss: 0.4490 - val_accuracy: 0.8361\nEpoch 171/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.4324 - accuracy: 0.8369 - val_loss: 0.4288 - val_accuracy: 0.8613\nEpoch 172/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.4211 - accuracy: 0.8467 - val_loss: 0.3910 - val_accuracy: 0.8613\nEpoch 173/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.3960 - accuracy: 0.8537 - val_loss: 0.3948 - val_accuracy: 0.8739\nEpoch 174/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.4100 - accuracy: 0.8486 - val_loss: 0.3871 - val_accuracy: 0.8613\nEpoch 175/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.4078 - accuracy: 0.8486 - val_loss: 0.4060 - val_accuracy: 0.8487\nEpoch 176/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.3835 - accuracy: 0.8612 - val_loss: 0.4554 - val_accuracy: 0.8319\nEpoch 177/400\n67/67 [==============================] - 3s 51ms/step - loss: 0.4018 - accuracy: 0.8519 - val_loss: 0.4457 - val_accuracy: 0.8445\nEpoch 178/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3974 - accuracy: 0.8570 - val_loss: 0.4381 - val_accuracy: 0.8487\nEpoch 179/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.4161 - accuracy: 0.8547 - val_loss: 0.4200 - val_accuracy: 0.8571\nEpoch 180/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3984 - accuracy: 0.8621 - val_loss: 0.4307 - val_accuracy: 0.8739\nEpoch 181/400\n67/67 [==============================] - 3s 45ms/step - loss: 0.4051 - accuracy: 0.8584 - val_loss: 0.4200 - val_accuracy: 0.8571\nEpoch 182/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.4071 - accuracy: 0.8439 - val_loss: 0.4330 - val_accuracy: 0.8487\nEpoch 183/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.3999 - accuracy: 0.8519 - val_loss: 0.4982 - val_accuracy: 0.8403\nEpoch 184/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3923 - accuracy: 0.8561 - val_loss: 0.3917 - val_accuracy: 0.8739\nEpoch 185/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.3909 - accuracy: 0.8650 - val_loss: 0.4322 - val_accuracy: 0.8487\nEpoch 186/400\n67/67 [==============================] - 3s 46ms/step - loss: 0.3775 - accuracy: 0.8621 - val_loss: 0.4363 - val_accuracy: 0.8445\nEpoch 187/400\n67/67 [==============================] - 4s 52ms/step - loss: 0.3931 - accuracy: 0.8542 - val_loss: 0.4294 - val_accuracy: 0.8445\nEpoch 188/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3879 - accuracy: 0.8514 - val_loss: 0.4760 - val_accuracy: 0.8319\nEpoch 189/400\n67/67 [==============================] - 3s 45ms/step - loss: 0.3776 - accuracy: 0.8682 - val_loss: 0.4101 - val_accuracy: 0.8487\nEpoch 190/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3953 - accuracy: 0.8505 - val_loss: 0.4310 - val_accuracy: 0.8445\nEpoch 191/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3823 - accuracy: 0.8603 - val_loss: 0.4103 - val_accuracy: 0.8445\nEpoch 192/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.3541 - accuracy: 0.8724 - val_loss: 0.4349 - val_accuracy: 0.8613\nEpoch 193/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.3997 - accuracy: 0.8477 - val_loss: 0.4304 - val_accuracy: 0.8403\nEpoch 194/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.4025 - accuracy: 0.8495 - val_loss: 0.4157 - val_accuracy: 0.8487\nEpoch 195/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3802 - accuracy: 0.8626 - val_loss: 0.4296 - val_accuracy: 0.8403\nEpoch 196/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.3681 - accuracy: 0.8668 - val_loss: 0.4035 - val_accuracy: 0.8613\nEpoch 197/400\n67/67 [==============================] - 3s 51ms/step - loss: 0.3775 - accuracy: 0.8654 - val_loss: 0.4130 - val_accuracy: 0.8529\nEpoch 198/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.3832 - accuracy: 0.8584 - val_loss: 0.3940 - val_accuracy: 0.8529\nEpoch 199/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.4043 - accuracy: 0.8528 - val_loss: 0.4035 - val_accuracy: 0.8529\nEpoch 200/400\n67/67 [==============================] - 3s 50ms/step - loss: 0.3624 - accuracy: 0.8701 - val_loss: 0.4396 - val_accuracy: 0.8445\nEpoch 201/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3824 - accuracy: 0.8584 - val_loss: 0.4492 - val_accuracy: 0.8529\nEpoch 202/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3854 - accuracy: 0.8575 - val_loss: 0.4154 - val_accuracy: 0.8655\nEpoch 203/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3628 - accuracy: 0.8668 - val_loss: 0.4310 - val_accuracy: 0.8655\nEpoch 204/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.3854 - accuracy: 0.8645 - val_loss: 0.4423 - val_accuracy: 0.8403\nEpoch 205/400\n67/67 [==============================] - 3s 41ms/step - loss: 0.4007 - accuracy: 0.8514 - val_loss: 0.4161 - val_accuracy: 0.8655\nEpoch 206/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3470 - accuracy: 0.8659 - val_loss: 0.4170 - val_accuracy: 0.8571\nEpoch 207/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3590 - accuracy: 0.8748 - val_loss: 0.4175 - val_accuracy: 0.8571\nEpoch 208/400\n67/67 [==============================] - 4s 57ms/step - loss: 0.3727 - accuracy: 0.8664 - val_loss: 0.4181 - val_accuracy: 0.8487\nEpoch 209/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3706 - accuracy: 0.8626 - val_loss: 0.4054 - val_accuracy: 0.8529\nEpoch 210/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.3787 - accuracy: 0.8636 - val_loss: 0.4028 - val_accuracy: 0.8655\nEpoch 211/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.3577 - accuracy: 0.8715 - val_loss: 0.3883 - val_accuracy: 0.8655\nEpoch 212/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3675 - accuracy: 0.8626 - val_loss: 0.3951 - val_accuracy: 0.8571\nEpoch 213/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3741 - accuracy: 0.8692 - val_loss: 0.4780 - val_accuracy: 0.8487\nEpoch 214/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3884 - accuracy: 0.8565 - val_loss: 0.4268 - val_accuracy: 0.8403\nEpoch 215/400\n67/67 [==============================] - 3s 46ms/step - loss: 0.3768 - accuracy: 0.8626 - val_loss: 0.4045 - val_accuracy: 0.8613\nEpoch 216/400\n67/67 [==============================] - 3s 41ms/step - loss: 0.3695 - accuracy: 0.8621 - val_loss: 0.4248 - val_accuracy: 0.8571\nEpoch 217/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3446 - accuracy: 0.8724 - val_loss: 0.3655 - val_accuracy: 0.8655\nEpoch 218/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3801 - accuracy: 0.8678 - val_loss: 0.4159 - val_accuracy: 0.8487\nEpoch 219/400\n67/67 [==============================] - 4s 58ms/step - loss: 0.3676 - accuracy: 0.8617 - val_loss: 0.4259 - val_accuracy: 0.8739\nEpoch 220/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3730 - accuracy: 0.8626 - val_loss: 0.4468 - val_accuracy: 0.8403\nEpoch 221/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3420 - accuracy: 0.8832 - val_loss: 0.4200 - val_accuracy: 0.8655\nEpoch 222/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.3509 - accuracy: 0.8762 - val_loss: 0.4267 - val_accuracy: 0.8445\nEpoch 223/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3412 - accuracy: 0.8743 - val_loss: 0.4142 - val_accuracy: 0.8529\nEpoch 224/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3640 - accuracy: 0.8617 - val_loss: 0.4280 - val_accuracy: 0.8571\nEpoch 225/400\n67/67 [==============================] - 3s 41ms/step - loss: 0.3499 - accuracy: 0.8668 - val_loss: 0.4011 - val_accuracy: 0.8697\nEpoch 226/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.3612 - accuracy: 0.8626 - val_loss: 0.4126 - val_accuracy: 0.8445\nEpoch 227/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.3523 - accuracy: 0.8645 - val_loss: 0.4147 - val_accuracy: 0.8403\nEpoch 228/400\n67/67 [==============================] - 3s 45ms/step - loss: 0.3596 - accuracy: 0.8766 - val_loss: 0.4195 - val_accuracy: 0.8571\nEpoch 229/400\n67/67 [==============================] - 3s 52ms/step - loss: 0.3433 - accuracy: 0.8724 - val_loss: 0.4314 - val_accuracy: 0.8487\nEpoch 230/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.3419 - accuracy: 0.8743 - val_loss: 0.4123 - val_accuracy: 0.8403\nEpoch 231/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3535 - accuracy: 0.8715 - val_loss: 0.4580 - val_accuracy: 0.8277\nEpoch 232/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3600 - accuracy: 0.8673 - val_loss: 0.4294 - val_accuracy: 0.8487\nEpoch 233/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.3472 - accuracy: 0.8673 - val_loss: 0.4622 - val_accuracy: 0.8487\nEpoch 234/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3541 - accuracy: 0.8720 - val_loss: 0.4174 - val_accuracy: 0.8487\nEpoch 235/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3574 - accuracy: 0.8654 - val_loss: 0.4442 - val_accuracy: 0.8571\nEpoch 236/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3367 - accuracy: 0.8762 - val_loss: 0.4022 - val_accuracy: 0.8739\nEpoch 237/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.3418 - accuracy: 0.8687 - val_loss: 0.4602 - val_accuracy: 0.8571\nEpoch 238/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3479 - accuracy: 0.8752 - val_loss: 0.4148 - val_accuracy: 0.8655\nEpoch 239/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.3571 - accuracy: 0.8626 - val_loss: 0.4792 - val_accuracy: 0.8487\nEpoch 240/400\n67/67 [==============================] - 3s 51ms/step - loss: 0.3646 - accuracy: 0.8724 - val_loss: 0.4206 - val_accuracy: 0.8571\nEpoch 241/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.3483 - accuracy: 0.8757 - val_loss: 0.3947 - val_accuracy: 0.8655\nEpoch 242/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3381 - accuracy: 0.8780 - val_loss: 0.4297 - val_accuracy: 0.8445\nEpoch 243/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3519 - accuracy: 0.8734 - val_loss: 0.4379 - val_accuracy: 0.8655\nEpoch 244/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.3222 - accuracy: 0.8841 - val_loss: 0.4270 - val_accuracy: 0.8445\nEpoch 245/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3559 - accuracy: 0.8762 - val_loss: 0.4244 - val_accuracy: 0.8571\nEpoch 246/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3488 - accuracy: 0.8780 - val_loss: 0.4225 - val_accuracy: 0.8824\nEpoch 247/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.3548 - accuracy: 0.8668 - val_loss: 0.4079 - val_accuracy: 0.8613\nEpoch 248/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.3404 - accuracy: 0.8757 - val_loss: 0.4439 - val_accuracy: 0.8445\nEpoch 249/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3441 - accuracy: 0.8813 - val_loss: 0.4155 - val_accuracy: 0.8403\nEpoch 250/400\n67/67 [==============================] - 3s 52ms/step - loss: 0.3410 - accuracy: 0.8692 - val_loss: 0.4077 - val_accuracy: 0.8571\nEpoch 251/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3576 - accuracy: 0.8692 - val_loss: 0.4220 - val_accuracy: 0.8529\nEpoch 252/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.3382 - accuracy: 0.8701 - val_loss: 0.4142 - val_accuracy: 0.8613\nEpoch 253/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3386 - accuracy: 0.8678 - val_loss: 0.4430 - val_accuracy: 0.8487\nEpoch 254/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.3365 - accuracy: 0.8752 - val_loss: 0.4629 - val_accuracy: 0.8571\nEpoch 255/400\n67/67 [==============================] - 3s 46ms/step - loss: 0.3288 - accuracy: 0.8799 - val_loss: 0.4243 - val_accuracy: 0.8613\nEpoch 256/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3476 - accuracy: 0.8757 - val_loss: 0.4418 - val_accuracy: 0.8445\nEpoch 257/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3473 - accuracy: 0.8724 - val_loss: 0.4284 - val_accuracy: 0.8403\nEpoch 258/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3034 - accuracy: 0.8841 - val_loss: 0.4285 - val_accuracy: 0.8529\nEpoch 259/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.3549 - accuracy: 0.8706 - val_loss: 0.4323 - val_accuracy: 0.8613\nEpoch 260/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.3468 - accuracy: 0.8650 - val_loss: 0.4414 - val_accuracy: 0.8613\nEpoch 261/400\n67/67 [==============================] - 3s 50ms/step - loss: 0.3474 - accuracy: 0.8715 - val_loss: 0.4159 - val_accuracy: 0.8613\nEpoch 262/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3556 - accuracy: 0.8729 - val_loss: 0.3936 - val_accuracy: 0.8445\nEpoch 263/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.3170 - accuracy: 0.8832 - val_loss: 0.4414 - val_accuracy: 0.8613\nEpoch 264/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3221 - accuracy: 0.8743 - val_loss: 0.4407 - val_accuracy: 0.8277\nEpoch 265/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3356 - accuracy: 0.8734 - val_loss: 0.4292 - val_accuracy: 0.8487\nEpoch 266/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.3460 - accuracy: 0.8720 - val_loss: 0.4164 - val_accuracy: 0.8529\nEpoch 267/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3102 - accuracy: 0.8822 - val_loss: 0.4172 - val_accuracy: 0.8361\nEpoch 268/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3230 - accuracy: 0.8799 - val_loss: 0.3933 - val_accuracy: 0.8571\nEpoch 269/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3300 - accuracy: 0.8780 - val_loss: 0.4293 - val_accuracy: 0.8319\nEpoch 270/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.3350 - accuracy: 0.8729 - val_loss: 0.4068 - val_accuracy: 0.8613\nEpoch 271/400\n67/67 [==============================] - 4s 53ms/step - loss: 0.3222 - accuracy: 0.8715 - val_loss: 0.4123 - val_accuracy: 0.8361\nEpoch 272/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3168 - accuracy: 0.8874 - val_loss: 0.4785 - val_accuracy: 0.8403\nEpoch 273/400\n67/67 [==============================] - 3s 41ms/step - loss: 0.3199 - accuracy: 0.8813 - val_loss: 0.4083 - val_accuracy: 0.8613\nEpoch 274/400\n67/67 [==============================] - 3s 50ms/step - loss: 0.3142 - accuracy: 0.8799 - val_loss: 0.4785 - val_accuracy: 0.8655\nEpoch 275/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3425 - accuracy: 0.8762 - val_loss: 0.4062 - val_accuracy: 0.8529\nEpoch 276/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3261 - accuracy: 0.8724 - val_loss: 0.4246 - val_accuracy: 0.8613\nEpoch 277/400\n67/67 [==============================] - 3s 49ms/step - loss: 0.3308 - accuracy: 0.8757 - val_loss: 0.3992 - val_accuracy: 0.8613\nEpoch 278/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3416 - accuracy: 0.8701 - val_loss: 0.4285 - val_accuracy: 0.8571\nEpoch 279/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3246 - accuracy: 0.8780 - val_loss: 0.4245 - val_accuracy: 0.8487\nEpoch 280/400\n67/67 [==============================] - 3s 41ms/step - loss: 0.3359 - accuracy: 0.8673 - val_loss: 0.4325 - val_accuracy: 0.8613\nEpoch 281/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.3229 - accuracy: 0.8780 - val_loss: 0.4457 - val_accuracy: 0.8319\nEpoch 282/400\n67/67 [==============================] - 3s 50ms/step - loss: 0.3049 - accuracy: 0.8850 - val_loss: 0.4290 - val_accuracy: 0.8655\nEpoch 283/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3240 - accuracy: 0.8813 - val_loss: 0.4616 - val_accuracy: 0.8403\nEpoch 284/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.3209 - accuracy: 0.8720 - val_loss: 0.4008 - val_accuracy: 0.8697\nEpoch 285/400\n67/67 [==============================] - 3s 46ms/step - loss: 0.3103 - accuracy: 0.8893 - val_loss: 0.4353 - val_accuracy: 0.8571\nEpoch 286/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3141 - accuracy: 0.8785 - val_loss: 0.4357 - val_accuracy: 0.8529\nEpoch 287/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3031 - accuracy: 0.8841 - val_loss: 0.4676 - val_accuracy: 0.8697\nEpoch 288/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.3193 - accuracy: 0.8752 - val_loss: 0.4534 - val_accuracy: 0.8445\nEpoch 289/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.2923 - accuracy: 0.8883 - val_loss: 0.4071 - val_accuracy: 0.8571\nEpoch 290/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3273 - accuracy: 0.8836 - val_loss: 0.4292 - val_accuracy: 0.8487\nEpoch 291/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3355 - accuracy: 0.8720 - val_loss: 0.4296 - val_accuracy: 0.8571\nEpoch 292/400\n67/67 [==============================] - 4s 56ms/step - loss: 0.3059 - accuracy: 0.8874 - val_loss: 0.4887 - val_accuracy: 0.8235\nEpoch 293/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.2878 - accuracy: 0.8911 - val_loss: 0.5161 - val_accuracy: 0.8445\nEpoch 294/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3058 - accuracy: 0.8855 - val_loss: 0.4335 - val_accuracy: 0.8487\nEpoch 295/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3123 - accuracy: 0.8827 - val_loss: 0.4128 - val_accuracy: 0.8445\nEpoch 296/400\n67/67 [==============================] - 3s 46ms/step - loss: 0.3144 - accuracy: 0.8804 - val_loss: 0.4052 - val_accuracy: 0.8487\nEpoch 297/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.2974 - accuracy: 0.8874 - val_loss: 0.4553 - val_accuracy: 0.8571\nEpoch 298/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.2903 - accuracy: 0.8883 - val_loss: 0.4172 - val_accuracy: 0.8529\nEpoch 299/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3295 - accuracy: 0.8701 - val_loss: 0.4745 - val_accuracy: 0.8529\nEpoch 302/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3147 - accuracy: 0.8827 - val_loss: 0.3965 - val_accuracy: 0.8487\nEpoch 303/400\n67/67 [==============================] - 4s 59ms/step - loss: 0.3109 - accuracy: 0.8836 - val_loss: 0.4573 - val_accuracy: 0.8445\nEpoch 304/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.2991 - accuracy: 0.8939 - val_loss: 0.4972 - val_accuracy: 0.8319\nEpoch 305/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3088 - accuracy: 0.8864 - val_loss: 0.4302 - val_accuracy: 0.8361\nEpoch 306/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.2986 - accuracy: 0.8864 - val_loss: 0.4511 - val_accuracy: 0.8487\nEpoch 307/400\n67/67 [==============================] - 3s 45ms/step - loss: 0.3059 - accuracy: 0.8869 - val_loss: 0.4334 - val_accuracy: 0.8403\nEpoch 308/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3124 - accuracy: 0.8855 - val_loss: 0.4661 - val_accuracy: 0.8361\nEpoch 309/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3011 - accuracy: 0.8790 - val_loss: 0.4405 - val_accuracy: 0.8487\nEpoch 310/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.3055 - accuracy: 0.8827 - val_loss: 0.4581 - val_accuracy: 0.8361\nEpoch 311/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3132 - accuracy: 0.8813 - val_loss: 0.4474 - val_accuracy: 0.8445\nEpoch 312/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3221 - accuracy: 0.8771 - val_loss: 0.4551 - val_accuracy: 0.8487\nEpoch 313/400\n67/67 [==============================] - 3s 52ms/step - loss: 0.2962 - accuracy: 0.8850 - val_loss: 0.4190 - val_accuracy: 0.8487\nEpoch 314/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.2957 - accuracy: 0.8832 - val_loss: 0.4517 - val_accuracy: 0.8571\nEpoch 315/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.2979 - accuracy: 0.8879 - val_loss: 0.3983 - val_accuracy: 0.8529\nEpoch 316/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3148 - accuracy: 0.8776 - val_loss: 0.4431 - val_accuracy: 0.8487\nEpoch 317/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.2826 - accuracy: 0.8874 - val_loss: 0.4160 - val_accuracy: 0.8613\nEpoch 318/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.2870 - accuracy: 0.8925 - val_loss: 0.4071 - val_accuracy: 0.8571\nEpoch 319/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.2892 - accuracy: 0.8850 - val_loss: 0.4376 - val_accuracy: 0.8571\nEpoch 320/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.2973 - accuracy: 0.8883 - val_loss: 0.4821 - val_accuracy: 0.8571\nEpoch 321/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.3111 - accuracy: 0.8850 - val_loss: 0.4114 - val_accuracy: 0.8571\nEpoch 322/400\n67/67 [==============================] - 3s 41ms/step - loss: 0.3200 - accuracy: 0.8813 - val_loss: 0.4324 - val_accuracy: 0.8487\nEpoch 323/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.2821 - accuracy: 0.8935 - val_loss: 0.4089 - val_accuracy: 0.8655\nEpoch 324/400\n67/67 [==============================] - 3s 52ms/step - loss: 0.2977 - accuracy: 0.8907 - val_loss: 0.4394 - val_accuracy: 0.8613\nEpoch 325/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.2878 - accuracy: 0.8883 - val_loss: 0.4812 - val_accuracy: 0.8361\nEpoch 326/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.2980 - accuracy: 0.8860 - val_loss: 0.4468 - val_accuracy: 0.8487\nEpoch 327/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.2949 - accuracy: 0.8916 - val_loss: 0.4023 - val_accuracy: 0.8613\nEpoch 328/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.2953 - accuracy: 0.8874 - val_loss: 0.4298 - val_accuracy: 0.8487\nEpoch 329/400\n67/67 [==============================] - 3s 50ms/step - loss: 0.2794 - accuracy: 0.9000 - val_loss: 0.4402 - val_accuracy: 0.8529\nEpoch 330/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.2943 - accuracy: 0.8883 - val_loss: 0.4220 - val_accuracy: 0.8571\nEpoch 331/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.2931 - accuracy: 0.8953 - val_loss: 0.3995 - val_accuracy: 0.8529\nEpoch 332/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.2687 - accuracy: 0.8958 - val_loss: 0.4187 - val_accuracy: 0.8613\nEpoch 333/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.3035 - accuracy: 0.8836 - val_loss: 0.4237 - val_accuracy: 0.8697\nEpoch 334/400\n67/67 [==============================] - 3s 52ms/step - loss: 0.3039 - accuracy: 0.8883 - val_loss: 0.4236 - val_accuracy: 0.8571\nEpoch 335/400\n67/67 [==============================] - 3s 41ms/step - loss: 0.2834 - accuracy: 0.8902 - val_loss: 0.4272 - val_accuracy: 0.8529\nEpoch 336/400\n67/67 [==============================] - 3s 49ms/step - loss: 0.2744 - accuracy: 0.8991 - val_loss: 0.4150 - val_accuracy: 0.8487\nEpoch 337/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.2810 - accuracy: 0.8935 - val_loss: 0.4639 - val_accuracy: 0.8277\nEpoch 338/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.2983 - accuracy: 0.8841 - val_loss: 0.4240 - val_accuracy: 0.8529\nEpoch 339/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.3064 - accuracy: 0.8864 - val_loss: 0.4117 - val_accuracy: 0.8529\nEpoch 340/400\n67/67 [==============================] - 3s 46ms/step - loss: 0.2876 - accuracy: 0.8907 - val_loss: 0.4057 - val_accuracy: 0.8571\nEpoch 341/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.2981 - accuracy: 0.8879 - val_loss: 0.4479 - val_accuracy: 0.8319\nEpoch 342/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.2780 - accuracy: 0.8944 - val_loss: 0.4727 - val_accuracy: 0.8529\nEpoch 343/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.2742 - accuracy: 0.9042 - val_loss: 0.4485 - val_accuracy: 0.8319\nEpoch 344/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.3134 - accuracy: 0.8804 - val_loss: 0.4490 - val_accuracy: 0.8487\nEpoch 345/400\n67/67 [==============================] - 3s 51ms/step - loss: 0.2959 - accuracy: 0.8808 - val_loss: 0.4704 - val_accuracy: 0.8445\nEpoch 346/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.2672 - accuracy: 0.8972 - val_loss: 0.4844 - val_accuracy: 0.8529\nEpoch 347/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.2733 - accuracy: 0.8995 - val_loss: 0.4687 - val_accuracy: 0.8529\nEpoch 348/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.2975 - accuracy: 0.8925 - val_loss: 0.4766 - val_accuracy: 0.8277\nEpoch 349/400\n67/67 [==============================] - 3s 41ms/step - loss: 0.2639 - accuracy: 0.8967 - val_loss: 0.4480 - val_accuracy: 0.8655\nEpoch 350/400\n67/67 [==============================] - 3s 41ms/step - loss: 0.2690 - accuracy: 0.8991 - val_loss: 0.4965 - val_accuracy: 0.8487\nEpoch 351/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.2713 - accuracy: 0.8944 - val_loss: 0.4740 - val_accuracy: 0.8403\nEpoch 352/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.2859 - accuracy: 0.8874 - val_loss: 0.4397 - val_accuracy: 0.8403\nEpoch 353/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.2735 - accuracy: 0.8921 - val_loss: 0.4810 - val_accuracy: 0.8277\nEpoch 354/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.2837 - accuracy: 0.8935 - val_loss: 0.4688 - val_accuracy: 0.8529\nEpoch 355/400\n67/67 [==============================] - 3s 52ms/step - loss: 0.2745 - accuracy: 0.9009 - val_loss: 0.4304 - val_accuracy: 0.8613\nEpoch 356/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.2928 - accuracy: 0.8836 - val_loss: 0.4358 - val_accuracy: 0.8529\nEpoch 357/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.2600 - accuracy: 0.8995 - val_loss: 0.4553 - val_accuracy: 0.8403\nEpoch 358/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.2853 - accuracy: 0.8958 - val_loss: 0.4541 - val_accuracy: 0.8487\nEpoch 359/400\n67/67 [==============================] - 3s 41ms/step - loss: 0.2730 - accuracy: 0.8953 - val_loss: 0.4750 - val_accuracy: 0.8487\nEpoch 360/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.2690 - accuracy: 0.8995 - val_loss: 0.4793 - val_accuracy: 0.8403\nEpoch 361/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.2573 - accuracy: 0.9098 - val_loss: 0.4868 - val_accuracy: 0.8403\nEpoch 362/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.2837 - accuracy: 0.8869 - val_loss: 0.4682 - val_accuracy: 0.8571\nEpoch 363/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.2839 - accuracy: 0.8916 - val_loss: 0.4469 - val_accuracy: 0.8361\nEpoch 364/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.2843 - accuracy: 0.8921 - val_loss: 0.4375 - val_accuracy: 0.8445\nEpoch 365/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.2714 - accuracy: 0.8921 - val_loss: 0.5051 - val_accuracy: 0.8445\nEpoch 366/400\n67/67 [==============================] - 3s 51ms/step - loss: 0.2690 - accuracy: 0.9009 - val_loss: 0.4809 - val_accuracy: 0.8277\nEpoch 367/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.2818 - accuracy: 0.8967 - val_loss: 0.4593 - val_accuracy: 0.8487\nEpoch 368/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.2678 - accuracy: 0.8944 - val_loss: 0.4535 - val_accuracy: 0.8445\nEpoch 369/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.2635 - accuracy: 0.8925 - val_loss: 0.5080 - val_accuracy: 0.8403\nEpoch 370/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.2771 - accuracy: 0.8958 - val_loss: 0.4687 - val_accuracy: 0.8487\nEpoch 371/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.2556 - accuracy: 0.9009 - val_loss: 0.4525 - val_accuracy: 0.8529\nEpoch 372/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.2764 - accuracy: 0.8967 - val_loss: 0.4551 - val_accuracy: 0.8529\nEpoch 373/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.2476 - accuracy: 0.9051 - val_loss: 0.4378 - val_accuracy: 0.8571\nEpoch 374/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.2544 - accuracy: 0.9028 - val_loss: 0.4618 - val_accuracy: 0.8403\nEpoch 375/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.2600 - accuracy: 0.9019 - val_loss: 0.4988 - val_accuracy: 0.8529\nEpoch 376/400\n67/67 [==============================] - 4s 55ms/step - loss: 0.2514 - accuracy: 0.8963 - val_loss: 0.4214 - val_accuracy: 0.8655\nEpoch 377/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.2598 - accuracy: 0.8949 - val_loss: 0.4099 - val_accuracy: 0.8529\nEpoch 378/400\n67/67 [==============================] - 3s 41ms/step - loss: 0.2679 - accuracy: 0.9014 - val_loss: 0.4469 - val_accuracy: 0.8403\nEpoch 379/400\n67/67 [==============================] - 3s 41ms/step - loss: 0.2690 - accuracy: 0.8981 - val_loss: 0.4280 - val_accuracy: 0.8571\nEpoch 380/400\n67/67 [==============================] - 3s 45ms/step - loss: 0.2762 - accuracy: 0.9000 - val_loss: 0.5105 - val_accuracy: 0.8445\nEpoch 381/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.2736 - accuracy: 0.8977 - val_loss: 0.4344 - val_accuracy: 0.8529\nEpoch 382/400\n67/67 [==============================] - 3s 40ms/step - loss: 0.2578 - accuracy: 0.8991 - val_loss: 0.4849 - val_accuracy: 0.8361\nEpoch 383/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.2543 - accuracy: 0.9005 - val_loss: 0.4891 - val_accuracy: 0.8529\nEpoch 384/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.2714 - accuracy: 0.8949 - val_loss: 0.4664 - val_accuracy: 0.8487\nEpoch 385/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.2695 - accuracy: 0.8986 - val_loss: 0.4468 - val_accuracy: 0.8487\nEpoch 386/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.2468 - accuracy: 0.9065 - val_loss: 0.4498 - val_accuracy: 0.8445\nEpoch 387/400\n67/67 [==============================] - 4s 57ms/step - loss: 0.2515 - accuracy: 0.9037 - val_loss: 0.4695 - val_accuracy: 0.8529\nEpoch 388/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.2496 - accuracy: 0.8972 - val_loss: 0.4396 - val_accuracy: 0.8529\nEpoch 389/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.2602 - accuracy: 0.9070 - val_loss: 0.4471 - val_accuracy: 0.8487\nEpoch 390/400\n67/67 [==============================] - 3s 41ms/step - loss: 0.2791 - accuracy: 0.9005 - val_loss: 0.4637 - val_accuracy: 0.8529\nEpoch 391/400\n67/67 [==============================] - 3s 48ms/step - loss: 0.2586 - accuracy: 0.9047 - val_loss: 0.4422 - val_accuracy: 0.8445\nEpoch 392/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.2416 - accuracy: 0.9047 - val_loss: 0.4811 - val_accuracy: 0.8445\nEpoch 393/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.2580 - accuracy: 0.9042 - val_loss: 0.4863 - val_accuracy: 0.8613\nEpoch 394/400\n67/67 [==============================] - 3s 42ms/step - loss: 0.2593 - accuracy: 0.8935 - val_loss: 0.4882 - val_accuracy: 0.8529\nEpoch 395/400\n67/67 [==============================] - 3s 47ms/step - loss: 0.2466 - accuracy: 0.9070 - val_loss: 0.4987 - val_accuracy: 0.8319\nEpoch 396/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.2424 - accuracy: 0.9061 - val_loss: 0.4807 - val_accuracy: 0.8445\nEpoch 397/400\n67/67 [==============================] - 3s 44ms/step - loss: 0.2552 - accuracy: 0.8995 - val_loss: 0.4641 - val_accuracy: 0.8571\nEpoch 398/400\n67/67 [==============================] - 4s 55ms/step - loss: 0.2589 - accuracy: 0.9023 - val_loss: 0.4809 - val_accuracy: 0.8487\nEpoch 399/400\n67/67 [==============================] - 3s 43ms/step - loss: 0.2505 - accuracy: 0.9033 - val_loss: 0.5011 - val_accuracy: 0.8445\nEpoch 400/400\n67/67 [==============================] - 3s 41ms/step - loss: 0.2696 - accuracy: 0.8939 - val_loss: 0.4695 - val_accuracy: 0.8361\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f14fdf27610>"},"metadata":{}}]},{"cell_type":"code","source":"from keras.models import load_model\nclassifier = load_model('./Vi_lstm_textclassifier.h5')","metadata":{"execution":{"iopub.status.busy":"2022-11-03T16:03:00.478481Z","iopub.execute_input":"2022-11-03T16:03:00.479125Z","iopub.status.idle":"2022-11-03T16:03:00.880382Z","shell.execute_reply.started":"2022-11-03T16:03:00.479087Z","shell.execute_reply":"2022-11-03T16:03:00.879344Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# label_encoder = preprocessing.LabelEncoder()\n# y_test_encode = label_encoder.fit_transform(y_test)\ny_pred = classifier.predict(X_test, batch_size=32, verbose=1)\ny_pred_bool = np.argmax(y_pred, axis=1)\ny_pred_txt = []\nlabel = pd.get_dummies(y_train).columns.tolist()\nfor y_pr in y_pred_bool:\n    y_pred_txt.append(label[y_pr])\nprint(classification_report(y_test, y_pred_txt))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h2iL_peF7Mjb","outputId":"e99a0a4a-32fb-4c6b-d666-3baafc526596","execution":{"iopub.status.busy":"2022-12-13T14:13:35.805052Z","iopub.execute_input":"2022-12-13T14:13:35.805419Z","iopub.status.idle":"2022-12-13T14:13:36.005340Z","shell.execute_reply.started":"2022-12-13T14:13:35.805389Z","shell.execute_reply":"2022-12-13T14:13:36.004316Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"19/19 [==============================] - 0s 4ms/step\n                         precision    recall  f1-score   support\n\n                  Other       0.76      0.75      0.75       100\n       du-lich_diem-den       0.88      0.92      0.90        53\n      giai-tri_gioi-sao       0.96      0.87      0.91        54\n       giao-duc_tin-tuc       0.88      0.98      0.93        59\n       khoa-hoc_tin-tuc       0.91      0.84      0.88        51\n      suc-khoe_cac-benh       0.76      0.92      0.83        49\n       suc-khoe_tin-tuc       0.94      0.81      0.87        59\n       the-thao_bong-da       0.96      0.88      0.92        60\n  the-thao_cac-mon-khac       1.00      0.95      0.97        58\nthe-thao_world-cup-2022       0.86      0.96      0.91        52\n\n               accuracy                           0.88       595\n              macro avg       0.89      0.89      0.89       595\n           weighted avg       0.88      0.88      0.88       595\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}