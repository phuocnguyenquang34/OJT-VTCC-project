{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b533004",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-12T04:26:48.808189Z",
     "iopub.status.busy": "2022-12-12T04:26:48.807263Z",
     "iopub.status.idle": "2022-12-12T04:27:11.155018Z",
     "shell.execute_reply": "2022-12-12T04:27:11.153841Z"
    },
    "papermill": {
     "duration": 22.363569,
     "end_time": "2022-12-12T04:27:11.158034",
     "exception": false,
     "start_time": "2022-12-12T04:26:48.794465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vncorenlp\r\n",
      "  Downloading vncorenlp-1.0.3.tar.gz (2.6 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from vncorenlp) (2.28.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->vncorenlp) (2022.9.24)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->vncorenlp) (3.3)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->vncorenlp) (2.1.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->vncorenlp) (1.26.12)\r\n",
      "Building wheels for collected packages: vncorenlp\r\n",
      "  Building wheel for vncorenlp (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-py3-none-any.whl size=2645951 sha256=5002caaac1536746f22424e1dc8172626af790711ea404c5b52fac267210fbef\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/0c/d8/f2/d28d97379b4f6479bf51247c8dfd57fa00932fa7a74b6aab29\r\n",
      "Successfully built vncorenlp\r\n",
      "Installing collected packages: vncorenlp\r\n",
      "Successfully installed vncorenlp-1.0.3\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.13.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.12)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.9.24)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.0)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install vncorenlp\n",
    "!pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb12017c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T04:27:11.171640Z",
     "iopub.status.busy": "2022-12-12T04:27:11.171327Z",
     "iopub.status.idle": "2022-12-12T04:27:25.086236Z",
     "shell.execute_reply": "2022-12-12T04:27:25.084170Z"
    },
    "papermill": {
     "duration": 13.925073,
     "end_time": "2022-12-12T04:27:25.089426",
     "exception": false,
     "start_time": "2022-12-12T04:27:11.164353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting GPUtil\r\n",
      "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hBuilding wheels for collected packages: GPUtil\r\n",
      "  Building wheel for GPUtil (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=e23b1b73781d2de58446bf31ca8a7101f9ba127b3ca62109c8b1e25f5fe7e1ef\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\r\n",
      "Successfully built GPUtil\r\n",
      "Installing collected packages: GPUtil\r\n",
      "Successfully installed GPUtil-1.4.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mInitial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  9% |  2% |\n"
     ]
    }
   ],
   "source": [
    "!pip install GPUtil\n",
    "\n",
    "import torch\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "\n",
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()                             \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "free_gpu_cache()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fccc44c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T04:27:25.104364Z",
     "iopub.status.busy": "2022-12-12T04:27:25.103507Z",
     "iopub.status.idle": "2022-12-12T04:27:32.115089Z",
     "shell.execute_reply": "2022-12-12T04:27:32.113915Z"
    },
    "papermill": {
     "duration": 7.021532,
     "end_time": "2022-12-12T04:27:32.117563",
     "exception": false,
     "start_time": "2022-12-12T04:27:25.096031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from vncorenlp import VnCoreNLP\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import os\n",
    "from transformers import RobertaForSequenceClassification, RobertaConfig, AdamW, RobertaTokenizer, RobertaTokenizerFast, RobertaModel, AutoTokenizer\n",
    "from datetime import datetime\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35a618a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T04:27:32.131861Z",
     "iopub.status.busy": "2022-12-12T04:27:32.131552Z",
     "iopub.status.idle": "2022-12-12T04:27:32.137245Z",
     "shell.execute_reply": "2022-12-12T04:27:32.136306Z"
    },
    "papermill": {
     "duration": 0.015238,
     "end_time": "2022-12-12T04:27:32.139430",
     "exception": false,
     "start_time": "2022-12-12T04:27:32.124192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def changeToOther(topic=''):\n",
    "    top_9_subtopic = csv['Topic'].value_counts()[:9].index.tolist()\n",
    "    if topic not in top_9_subtopic: return 'Other'\n",
    "    return topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "228d6e82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T04:27:32.152649Z",
     "iopub.status.busy": "2022-12-12T04:27:32.152379Z",
     "iopub.status.idle": "2022-12-12T04:27:35.803140Z",
     "shell.execute_reply": "2022-12-12T04:27:35.802166Z"
    },
    "papermill": {
     "duration": 3.659762,
     "end_time": "2022-12-12T04:27:35.805209",
     "exception": false,
     "start_time": "2022-12-12T04:27:32.145447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other                      500\n",
       "the-thao_bong-da           300\n",
       "giao-duc_tin-tuc           296\n",
       "the-thao_cac-mon-khac      292\n",
       "suc-khoe_tin-tuc           292\n",
       "giai-tri_gioi-sao          271\n",
       "du-lich_diem-den           264\n",
       "the-thao_world-cup-2022    259\n",
       "khoa-hoc_tin-tuc           253\n",
       "suc-khoe_cac-benh          246\n",
       "Name: Topic, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "csv = pd.read_csv('/kaggle/input/vne-sub-topic-1/Vne_sub_topic_1.csv')\n",
    "csv['Topic'] = csv['Topic'].apply(lambda x: changeToOther(x))\n",
    "csv = csv.sample(frac=1)\n",
    "csv[csv['Topic'] == 'Other'] = csv[csv['Topic'] == 'Other'][:500]\n",
    "csv = csv.dropna()\n",
    "csv['Topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d443c2db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T04:27:35.821409Z",
     "iopub.status.busy": "2022-12-12T04:27:35.819619Z",
     "iopub.status.idle": "2022-12-12T04:27:35.827497Z",
     "shell.execute_reply": "2022-12-12T04:27:35.826591Z"
    },
    "papermill": {
     "duration": 0.017527,
     "end_time": "2022-12-12T04:27:35.829560",
     "exception": false,
     "start_time": "2022-12-12T04:27:35.812033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = csv[['Content', 'Topic']]\n",
    "dataset = dataset.sample(frac=1)\n",
    "data = dataset['Content']\n",
    "label = dataset['Topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13523290",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T04:27:35.843225Z",
     "iopub.status.busy": "2022-12-12T04:27:35.842942Z",
     "iopub.status.idle": "2022-12-12T04:27:41.309936Z",
     "shell.execute_reply": "2022-12-12T04:27:41.308802Z"
    },
    "papermill": {
     "duration": 5.477494,
     "end_time": "2022-12-12T04:27:41.313301",
     "exception": false,
     "start_time": "2022-12-12T04:27:35.835807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vncorenlp import VnCoreNLP\n",
    "rdrsegmenter = VnCoreNLP(\"/kaggle/input/vncorenlp/vncorenlp/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "871a5f34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T04:27:41.334208Z",
     "iopub.status.busy": "2022-12-12T04:27:41.333868Z",
     "iopub.status.idle": "2022-12-12T04:27:41.340828Z",
     "shell.execute_reply": "2022-12-12T04:27:41.339946Z"
    },
    "papermill": {
     "duration": 0.019303,
     "end_time": "2022-12-12T04:27:41.342892",
     "exception": false,
     "start_time": "2022-12-12T04:27:41.323589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "# Text preprocessing \n",
    "def text_preprocessing(text=''):\n",
    "  text = text.lower()\n",
    "  text = text.translate(text.maketrans(string.punctuation, ' '*len(string.punctuation)))\n",
    "  text = re.sub('\\s+', ' ', text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a35b681",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T04:27:41.357260Z",
     "iopub.status.busy": "2022-12-12T04:27:41.356972Z",
     "iopub.status.idle": "2022-12-12T04:28:22.462139Z",
     "shell.execute_reply": "2022-12-12T04:28:22.461144Z"
    },
    "papermill": {
     "duration": 41.115192,
     "end_time": "2022-12-12T04:28:22.464713",
     "exception": false,
     "start_time": "2022-12-12T04:27:41.349521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = data.apply(lambda x: ' '.join([' '.join(sent) for sent in rdrsegmenter.tokenize(text_preprocessing(x))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d360459d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T04:28:22.479721Z",
     "iopub.status.busy": "2022-12-12T04:28:22.479094Z",
     "iopub.status.idle": "2022-12-12T04:28:22.505502Z",
     "shell.execute_reply": "2022-12-12T04:28:22.504596Z"
    },
    "papermill": {
     "duration": 0.035938,
     "end_time": "2022-12-12T04:28:22.507735",
     "exception": false,
     "start_time": "2022-12-12T04:28:22.471797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, label, test_size=0.2, random_state=42, stratify=label)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24bf7717",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T04:28:22.521935Z",
     "iopub.status.busy": "2022-12-12T04:28:22.521624Z",
     "iopub.status.idle": "2022-12-12T04:28:22.527123Z",
     "shell.execute_reply": "2022-12-12T04:28:22.526094Z"
    },
    "papermill": {
     "duration": 0.015039,
     "end_time": "2022-12-12T04:28:22.529273",
     "exception": false,
     "start_time": "2022-12-12T04:28:22.514234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_mask(batch_ids):\n",
    "    batch_mask = []\n",
    "    for ids in batch_ids:\n",
    "        mask = [int(token_id > 0) for token_id in ids]\n",
    "        batch_mask.append(mask)\n",
    "    return torch.tensor(batch_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfc5bcef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T04:28:22.544969Z",
     "iopub.status.busy": "2022-12-12T04:28:22.543528Z",
     "iopub.status.idle": "2022-12-12T04:28:22.556168Z",
     "shell.execute_reply": "2022-12-12T04:28:22.555269Z"
    },
    "papermill": {
     "duration": 0.021878,
     "end_time": "2022-12-12T04:28:22.558146",
     "exception": false,
     "start_time": "2022-12-12T04:28:22.536268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dataloader_from_text(texts=[], y=[], tokenizer=None, classes=[], savetodisk=None, loadformdisk=None, segment=False, max_len=256, batch_size=16, infer=False):\n",
    "    ids_padded, masks, labels = [], [], []\n",
    "    if loadformdisk == None:\n",
    "        #segementer\n",
    "#         if segment:\n",
    "#             rdrsegmenter = VnCoreNLP(\"/kaggle/input/vncorenlp/vncorenlp/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m')\n",
    "#         texts = []\n",
    "        print(\"LOADDING TEXT FILE\")\n",
    "#         with open(text_file, 'r') as f_r:\n",
    "#             for sample in tqdm(f_r):\n",
    "#                 if infer:\n",
    "#                     text = sample.strip()\n",
    "#                     if segment:\n",
    "#                             text = rdrsegmenter.tokenize(text)\n",
    "#                             text = ' '.join([' '.join(x) for x in text])\n",
    "#                     texts.append(text)\n",
    "#                 else:\n",
    "#                     splits = sample.strip().split(\" \",1)\n",
    "#                     label = classes.index(splits[0])\n",
    "#                     text = splits[1]\n",
    "#                     if segment:\n",
    "#                         text = rdrsegmenter.tokenize(text)\n",
    "#                         text = ' '.join([' '.join(x) for x in text])\n",
    "#                     labels.append(label)\n",
    "#                     texts.append(text)\n",
    "        for label in y:\n",
    "            labels.append(classes.index(label))\n",
    "\n",
    "        print(\"TEXT TO IDS\")\n",
    "        ids = []\n",
    "        for text in tqdm(texts):\n",
    "            encoded_sent = tokenizer.encode(text)\n",
    "            ids.append(encoded_sent)\n",
    "\n",
    "        del texts\n",
    "        # print(\"PADDING IDS\")\n",
    "        ids_padded = pad_sequences(ids, maxlen=max_len, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
    "        del ids\n",
    "        # print(\"CREATE MASK\")\n",
    "        # for sent in tqdm(ids_padded):\n",
    "        #     masks.append(make_mask(sent))\n",
    "\n",
    "        if savetodisk != None and not infer:\n",
    "            with open(savetodisk, 'wb') as f:\n",
    "                pickle.dump(ids_padded, f)\n",
    "                # pickle.dump(masks, f)\n",
    "                pickle.dump(labels, f)\n",
    "            print(\"SAVED IDS DATA TO DISK\")\n",
    "    else:\n",
    "        print(\"LOAD FORM DISK\")\n",
    "        if loadformdisk != None:\n",
    "            try:\n",
    "                with open(savetodisk, 'rb') as f:\n",
    "                    ids_padded = pickle.load(ids_padded, f)\n",
    "                    # masks = pickle.load(masks, f)\n",
    "                    labels = pickle.load(labels, f)\n",
    "                print(\"LOADED IDS DATA FORM DISK\")\n",
    "            except:\n",
    "                print(\"LOAD DATA FORM DISK ERROR!\")\n",
    "                \n",
    "    print(\"CONVERT TO TORCH TENSOR\")\n",
    "    ids_inputs = torch.tensor(ids_padded)\n",
    "    del ids_padded\n",
    "    # masks = torch.tensor(masks)\n",
    "    if not infer:\n",
    "        labels = torch.tensor(labels)\n",
    "\n",
    "    print(\"CREATE DATALOADER\")\n",
    "    if infer:\n",
    "        # input_data = TensorDataset(ids_inputs, masks)\n",
    "        input_data = TensorDataset(ids_inputs)\n",
    "    else:\n",
    "        input_data = TensorDataset(ids_inputs, labels)\n",
    "        # input_data = TensorDataset(ids_inputs, masks, labels)\n",
    "    input_sampler = SequentialSampler(input_data)\n",
    "    dataloader = DataLoader(input_data, sampler=input_sampler, batch_size=batch_size)\n",
    "\n",
    "    print(\"len dataloader:\", len(dataloader))\n",
    "    print(\"LOAD DATA ALL DONE\")\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "171c9784",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T04:28:22.572745Z",
     "iopub.status.busy": "2022-12-12T04:28:22.571971Z",
     "iopub.status.idle": "2022-12-12T04:28:22.580218Z",
     "shell.execute_reply": "2022-12-12T04:28:22.579303Z"
    },
    "papermill": {
     "duration": 0.017632,
     "end_time": "2022-12-12T04:28:22.582318",
     "exception": false,
     "start_time": "2022-12-12T04:28:22.564686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ROBERTAClassifier(torch.nn.Module):\n",
    "    def __init__(self, num_labels, bert_model, dropout_rate=0.3):\n",
    "        super(ROBERTAClassifier, self).__init__()\n",
    "        if bert_model != None:\n",
    "            self.roberta = bert_model\n",
    "        else:\n",
    "            self.roberta = RobertaModel.from_pretrained(\"vinai/phobert-base\")\n",
    "        self.d1 = torch.nn.Dropout(dropout_rate)\n",
    "        self.l1 = torch.nn.Linear(768, 64)\n",
    "        self.bn1 = torch.nn.LayerNorm(64)\n",
    "        self.d2 = torch.nn.Dropout(dropout_rate)\n",
    "        self.l2 = torch.nn.Linear(64, num_labels)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, x = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = self.d1(x)\n",
    "        x = self.l1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = torch.nn.Tanh()(x)\n",
    "        x = self.d2(x)\n",
    "        x = self.l2(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c91801fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T04:28:22.596210Z",
     "iopub.status.busy": "2022-12-12T04:28:22.595952Z",
     "iopub.status.idle": "2022-12-12T04:28:22.602362Z",
     "shell.execute_reply": "2022-12-12T04:28:22.601313Z"
    },
    "papermill": {
     "duration": 0.015856,
     "end_time": "2022-12-12T04:28:22.604477",
     "exception": false,
     "start_time": "2022-12-12T04:28:22.588621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BERTClassifier(torch.nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        bert_classifier_config = RobertaConfig.from_pretrained(\n",
    "            \"/kaggle/input/phobert-base-transformers/PhoBERT_base_transformers/config.json\",\n",
    "            from_tf=False,\n",
    "            num_labels = num_labels,\n",
    "            output_hidden_states=False,\n",
    "            )\n",
    "        print(\"LOAD BERT PRETRAIN MODEL\")\n",
    "        self.bert_classifier = RobertaForSequenceClassification.from_pretrained(\n",
    "            \"/kaggle/input/phobert-base-transformers/PhoBERT_base_transformers/model.bin\",\n",
    "            config=bert_classifier_config\n",
    "            )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels):\n",
    "        output = self.bert_classifier(input_ids=input_ids,\n",
    "                                    token_type_ids=None,\n",
    "                                    attention_mask=attention_mask,\n",
    "                                    labels=labels\n",
    "                                    )\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "905c9435",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T04:28:22.619002Z",
     "iopub.status.busy": "2022-12-12T04:28:22.618746Z",
     "iopub.status.idle": "2022-12-12T04:28:22.654290Z",
     "shell.execute_reply": "2022-12-12T04:28:22.653348Z"
    },
    "papermill": {
     "duration": 0.045234,
     "end_time": "2022-12-12T04:28:22.656303",
     "exception": false,
     "start_time": "2022-12-12T04:28:22.611069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ClassifierTrainner():\n",
    "    def __init__(self, bert_model, train_dataloader, valid_dataloader, epochs=10, cuda_device='cpu', save_dir=None):\n",
    "\n",
    "        if cuda_device == \"cpu\":\n",
    "            self.device == torch.device(\"cpu\")\n",
    "        else:\n",
    "            self.device = torch.device('cuda:{}'.format(cuda_device))\n",
    "\n",
    "        self.model = bert_model\n",
    "        if save_dir != None and os.path.exists(save_dir):\n",
    "            print(\"Load weight from file:{}\".format(save_dir))\n",
    "            self.save_dir = save_dir\n",
    "            epcho_checkpoint_path = glob.glob(\"{}/model_epoch*\".format(self.save_dir))\n",
    "            if len(epcho_checkpoint_path) == 0:\n",
    "                print(\"No checkpoint found in: {}\\nCheck save_dir...\".format(self.save_dir))\n",
    "            else:\n",
    "                self.load_checkpoint(epcho_checkpoint_path)\n",
    "                print(\"Restore weight successful from: {}\".format(epcho_checkpoint_path))\n",
    "        else:\n",
    "            self.save_dir = datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "            os.makedirs(self.save_dir)\n",
    "            print(\"Training new model, save to: {}\".format(self.save_dir))\n",
    "\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.epochs = epochs\n",
    "        # self.batch_size = batch_size\n",
    "\n",
    "    def save_checkpoint(self, save_path):\n",
    "        state_dict = {'model_state_dict': self.model.state_dict()}\n",
    "        torch.save(state_dict, save_path)\n",
    "        print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "    def load_checkpoint(self, load_path):\n",
    "        state_dict = torch.load(load_path, map_location=device)\n",
    "        print(f'Model restored from <== {load_path}')\n",
    "        self.model.load_state_dict(state_dict['model_state_dict'])\n",
    "\n",
    "    @staticmethod    \n",
    "    def flat_accuracy(preds, labels):\n",
    "        pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "        labels_flat = labels.flatten()\n",
    "        F1_score = f1_score(pred_flat, labels_flat, average='macro')\n",
    "        return accuracy_score(pred_flat, labels_flat), F1_score\n",
    "\n",
    "    def train_classifier(self):\n",
    "        self.model.to(self.device)\n",
    "        param_optimizer = list(self.model.named_parameters())\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "            ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5, correct_bias=False)\n",
    "\n",
    "        for epoch_i in range(0, self.epochs):\n",
    "            print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, self.epochs))\n",
    "            print('Training...')\n",
    "\n",
    "            total_loss = 0\n",
    "            self.model.train()\n",
    "            train_accuracy = 0\n",
    "            nb_train_steps = 0\n",
    "            train_f1 = 0\n",
    "            best_valid_loss = 999999\n",
    "            best_eval_accuracy = 0\n",
    "            for step, batch in enumerate(self.train_dataloader):\n",
    "                b_input_ids = batch[0].to(self.device)\n",
    "                b_input_mask = make_mask(batch[0]).to(self.device)\n",
    "                b_labels = batch[1].to(self.device)\n",
    "\n",
    "                self.model.zero_grad()\n",
    "                outputs = self.model(b_input_ids, \n",
    "                                    attention_mask=b_input_mask, \n",
    "                                    labels=b_labels\n",
    "                                    )\n",
    "                loss = outputs[0]\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                logits = outputs[1].detach().cpu().numpy()\n",
    "                label_ids = b_labels.cpu().numpy()\n",
    "                tmp_train_accuracy, tmp_train_f1 = self.flat_accuracy(logits, label_ids)\n",
    "                train_accuracy += tmp_train_accuracy\n",
    "                train_f1 += tmp_train_f1\n",
    "                nb_train_steps += 1\n",
    "                \n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                if step % 100 == 0:\n",
    "                    print(\"[TRAIN] Epoch {}/{} | Batch {}/{} | Train Loss={} | Train Acc={}\".format(epoch_i, self.epochs, step, len(self.train_dataloader), loss.item(), tmp_train_accuracy))\n",
    "                \n",
    "            avg_train_loss = total_loss / len(self.train_dataloader)\n",
    "            print(\" Train Accuracy: {0:.4f}\".format(train_accuracy/nb_train_steps))\n",
    "            print(\" Train F1 score: {0:.4f}\".format(train_f1/nb_train_steps))\n",
    "            print(\" Train Loss: {0:.4f}\".format(avg_train_loss))\n",
    "\n",
    "            print(\"Running Validation...\")\n",
    "            self.model.eval()\n",
    "            eval_loss, eval_accuracy = 0, 0\n",
    "            nb_eval_steps, nb_eval_examples = 0, 0\n",
    "            eval_f1 = 0\n",
    "\n",
    "            for batch in self.valid_dataloader:\n",
    "                b_input_mask = make_mask(batch[0]).to(self.device)\n",
    "                batch = tuple(t.to(self.device) for t in batch)\n",
    "                b_input_ids, b_labels = batch\n",
    "                with torch.no_grad():\n",
    "                    outputs = self.model(b_input_ids, \n",
    "                                        attention_mask=b_input_mask,\n",
    "                                        labels=b_labels\n",
    "                                        )\n",
    "                    tmp_eval_loss, logits = outputs[0], outputs[1]\n",
    "                    logits = logits.detach().cpu().numpy()\n",
    "                    label_ids = b_labels.cpu().numpy()\n",
    "                    tmp_eval_accuracy, tmp_eval_f1 = self.flat_accuracy(logits, label_ids)\n",
    "                    eval_accuracy += tmp_eval_accuracy\n",
    "                    eval_loss += tmp_eval_loss\n",
    "                    eval_f1 += tmp_eval_f1\n",
    "                    nb_eval_steps += 1\n",
    "\n",
    "            print(\" Valid Loss: {0:.4f}\".format(eval_loss/nb_eval_steps))\n",
    "            print(\" Valid Accuracy: {0:.4f}\".format(eval_accuracy/nb_eval_steps))\n",
    "            print(\" Valid F1 score: {0:.4f}\".format(eval_f1/nb_eval_steps))\n",
    "\n",
    "            if best_valid_loss > eval_loss:\n",
    "                best_valid_loss = eval_loss\n",
    "                best_valid_loss_path = \"{}/model_best_valoss.pt\".format(self.save_dir)\n",
    "                self.save_checkpoint(best_valid_loss_path)\n",
    "            if best_eval_accuracy > eval_accuracy:\n",
    "                best_eval_accuracy = eval_accuracy\n",
    "                best_eval_accuracy_path = \"{}/model_best_valacc.pt\".format(self.save_dir)\n",
    "                self.save_checkpoint(best_eval_accuracy_path)\n",
    "            \n",
    "            epoch_i_path = \"{}/model_epoch{}.pt\".format(self.save_dir, epoch_i)\n",
    "            self.save_checkpoint(epoch_i_path)\n",
    "            if epoch_i != 0: os.remove(\"{}/model_epoch{}.pt\".format(self.save_dir, epoch_i-1))\n",
    "\n",
    "        print(\"Training complete!\")\n",
    "\n",
    "    def predict_dataloader(self, dataloader, classes, tokenizer):\n",
    "        for batch in dataloader:\n",
    "            b_input_mask = make_mask(batch[0]).to(self.device)\n",
    "            batch = tuple(t.to(self.device) for t in batch)\n",
    "            b_input_ids = batch[0]\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(b_input_ids, \n",
    "                                    attention_mask=b_input_mask,\n",
    "                                    labels=None\n",
    "                                    )\n",
    "                logits = outputs\n",
    "                logits = logits.detach().cpu().numpy()\n",
    "                pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "                print(\"[PREDICT] {}:{}\".format(classes[int(pred_flat)], tokenizer.decode(b_input_ids)))\n",
    "\n",
    "    def predict_test(self, dataloader, classes, tokenizer):\n",
    "        pred, label, pred_txt, label_txt = [], [], [], []\n",
    "        for batch in dataloader:\n",
    "            b_input_mask = make_mask(batch[0]).to(self.device)\n",
    "            batch = tuple(t.to(self.device) for t in batch)\n",
    "            b_input_ids, b_labels = batch\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(b_input_ids, \n",
    "                                    attention_mask=b_input_mask,\n",
    "                                    labels=b_labels\n",
    "                                    )\n",
    "                tmp_eval_loss, logits = outputs[0], outputs[1]\n",
    "                logits = logits.detach().cpu().numpy()\n",
    "                label_ids = b_labels.cpu().numpy()\n",
    "                pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "                labels_flat = label_ids.flatten()\n",
    "                for y in pred_flat:\n",
    "                    pred.append(y)\n",
    "                for lab in labels_flat:\n",
    "                    label.append(lab)\n",
    "        for y_pr in pred:\n",
    "            pred_txt.append(classes[int(y_pr)])\n",
    "        for y_lab in label:\n",
    "            label_txt.append(classes[int(y_lab)])\n",
    "        print(classification_report(pred_txt, label_txt))\n",
    "        \n",
    "    def predict_text(self, text, classes, tokenizer, max_len=256):\n",
    "        ids = tokenizer.encode(text)\n",
    "#         ids_padded = pad_sequences(ids, maxlen=max_len, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
    "        ids_padded = pad_sequence(ids)\n",
    "        mask = [int(token_id > 0) for token_id in ids_padded]\n",
    "        input_ids = torch.tensor(ids_padded)\n",
    "        input_ids = torch.reshape(input_ids,(1,256)).to(self.device)\n",
    "        intput_mask = torch.tensor(mask)\n",
    "        intput_mask = torch.reshape(intput_mask,(1,256)).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(input_ids, \n",
    "                                attention_mask=intput_mask,\n",
    "                                labels=None\n",
    "                                )\n",
    "            logits = logits[0].detach().cpu().numpy()\n",
    "#             logits = logits.detach().cpu().numpy()\n",
    "            pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "            print(\"[PREDICT] {}:{}\".format(classes[int(pred_flat)], text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46a1a6cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T04:28:22.669642Z",
     "iopub.status.busy": "2022-12-12T04:28:22.669386Z",
     "iopub.status.idle": "2022-12-12T04:28:22.675516Z",
     "shell.execute_reply": "2022-12-12T04:28:22.674595Z"
    },
    "papermill": {
     "duration": 0.015109,
     "end_time": "2022-12-12T04:28:22.677586",
     "exception": false,
     "start_time": "2022-12-12T04:28:22.662477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad_sequence(input_ids, maxlen=256):\n",
    "    if len(input_ids) > maxlen: \n",
    "            input_ids = input_ids[:maxlen] \n",
    "    else:\n",
    "        input_ids = input_ids + [0]*(maxlen - len(input_ids))\n",
    "    output_ids = np.array(input_ids)\n",
    "    return output_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a18d4892",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T04:28:22.691302Z",
     "iopub.status.busy": "2022-12-12T04:28:22.691023Z",
     "iopub.status.idle": "2022-12-12T04:38:53.515348Z",
     "shell.execute_reply": "2022-12-12T04:38:53.513349Z"
    },
    "papermill": {
     "duration": 630.834589,
     "end_time": "2022-12-12T04:38:53.518353",
     "exception": false,
     "start_time": "2022-12-12T04:28:22.683764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a4138d960a4e90983e516b26afab9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/557 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9304841668d14fdb8266c8a8613239fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/874k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8b33ee4a494fe0a7f240cfb85a8946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADDING TEXT FILE\n",
      "TEXT TO IDS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2140 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (697 > 256). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 2140/2140 [00:06<00:00, 306.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONVERT TO TORCH TENSOR\n",
      "CREATE DATALOADER\n",
      "len dataloader: 134\n",
      "LOAD DATA ALL DONE\n",
      "LOADDING TEXT FILE\n",
      "TEXT TO IDS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 238/238 [00:00<00:00, 365.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONVERT TO TORCH TENSOR\n",
      "CREATE DATALOADER\n",
      "len dataloader: 15\n",
      "LOAD DATA ALL DONE\n",
      "LOADDING TEXT FILE\n",
      "TEXT TO IDS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 595/595 [00:01<00:00, 345.02it/s]\n",
      "You are using a model of type bert to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONVERT TO TORCH TENSOR\n",
      "CREATE DATALOADER\n",
      "len dataloader: 38\n",
      "LOAD DATA ALL DONE\n",
      "LOAD BERT PRETRAIN MODEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /kaggle/input/phobert-base-transformers/PhoBERT_base_transformers/model.bin were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'lm_head.bias', 'roberta.pooler.dense.weight', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/phobert-base-transformers/PhoBERT_base_transformers/model.bin and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training new model, save to: 12-12-2022_04-28-43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Epoch 1 / 10 ========\n",
      "Training...\n",
      "[TRAIN] Epoch 0/10 | Batch 0/134 | Train Loss=2.259617567062378 | Train Acc=0.0\n",
      "[TRAIN] Epoch 0/10 | Batch 100/134 | Train Loss=0.5928947925567627 | Train Acc=0.875\n",
      " Train Accuracy: 0.6775\n",
      " Train F1 score: 0.6046\n",
      " Train Loss: 1.1535\n",
      "Running Validation...\n",
      " Valid Loss: 0.6865\n",
      " Valid Accuracy: 0.8030\n",
      " Valid F1 score: 0.7310\n",
      "Model saved to ==> 12-12-2022_04-28-43/model_best_valoss.pt\n",
      "Model saved to ==> 12-12-2022_04-28-43/model_epoch0.pt\n",
      "======== Epoch 2 / 10 ========\n",
      "Training...\n",
      "[TRAIN] Epoch 1/10 | Batch 0/134 | Train Loss=0.9056756496429443 | Train Acc=0.6875\n",
      "[TRAIN] Epoch 1/10 | Batch 100/134 | Train Loss=0.18354474008083344 | Train Acc=1.0\n",
      " Train Accuracy: 0.8610\n",
      " Train F1 score: 0.8207\n",
      " Train Loss: 0.5045\n",
      "Running Validation...\n",
      " Valid Loss: 0.5090\n",
      " Valid Accuracy: 0.8494\n",
      " Valid F1 score: 0.7912\n",
      "Model saved to ==> 12-12-2022_04-28-43/model_best_valoss.pt\n",
      "Model saved to ==> 12-12-2022_04-28-43/model_epoch1.pt\n",
      "======== Epoch 3 / 10 ========\n",
      "Training...\n",
      "[TRAIN] Epoch 2/10 | Batch 0/134 | Train Loss=0.6076876521110535 | Train Acc=0.875\n",
      "[TRAIN] Epoch 2/10 | Batch 100/134 | Train Loss=0.11602431535720825 | Train Acc=1.0\n",
      " Train Accuracy: 0.9165\n",
      " Train F1 score: 0.8912\n",
      " Train Loss: 0.3310\n",
      "Running Validation...\n",
      " Valid Loss: 0.5376\n",
      " Valid Accuracy: 0.8411\n",
      " Valid F1 score: 0.7814\n",
      "Model saved to ==> 12-12-2022_04-28-43/model_best_valoss.pt\n",
      "Model saved to ==> 12-12-2022_04-28-43/model_epoch2.pt\n",
      "======== Epoch 4 / 10 ========\n",
      "Training...\n",
      "[TRAIN] Epoch 3/10 | Batch 0/134 | Train Loss=0.548624575138092 | Train Acc=0.875\n",
      "[TRAIN] Epoch 3/10 | Batch 100/134 | Train Loss=0.0410120002925396 | Train Acc=1.0\n",
      " Train Accuracy: 0.9356\n",
      " Train F1 score: 0.9149\n",
      " Train Loss: 0.2423\n",
      "Running Validation...\n",
      " Valid Loss: 0.6391\n",
      " Valid Accuracy: 0.8286\n",
      " Valid F1 score: 0.7721\n",
      "Model saved to ==> 12-12-2022_04-28-43/model_best_valoss.pt\n",
      "Model saved to ==> 12-12-2022_04-28-43/model_epoch3.pt\n",
      "======== Epoch 5 / 10 ========\n",
      "Training...\n",
      "[TRAIN] Epoch 4/10 | Batch 0/134 | Train Loss=0.5158566832542419 | Train Acc=0.875\n",
      "[TRAIN] Epoch 4/10 | Batch 100/134 | Train Loss=0.025985240936279297 | Train Acc=1.0\n",
      " Train Accuracy: 0.9543\n",
      " Train F1 score: 0.9406\n",
      " Train Loss: 0.1882\n",
      "Running Validation...\n",
      " Valid Loss: 0.6638\n",
      " Valid Accuracy: 0.8315\n",
      " Valid F1 score: 0.7659\n",
      "Model saved to ==> 12-12-2022_04-28-43/model_best_valoss.pt\n",
      "Model saved to ==> 12-12-2022_04-28-43/model_epoch4.pt\n",
      "======== Epoch 6 / 10 ========\n",
      "Training...\n",
      "[TRAIN] Epoch 5/10 | Batch 0/134 | Train Loss=0.578823983669281 | Train Acc=0.875\n",
      "[TRAIN] Epoch 5/10 | Batch 100/134 | Train Loss=0.018172098323702812 | Train Acc=1.0\n",
      " Train Accuracy: 0.9697\n",
      " Train F1 score: 0.9596\n",
      " Train Loss: 0.1262\n",
      "Running Validation...\n",
      " Valid Loss: 0.6107\n",
      " Valid Accuracy: 0.8363\n",
      " Valid F1 score: 0.7768\n",
      "Model saved to ==> 12-12-2022_04-28-43/model_best_valoss.pt\n",
      "Model saved to ==> 12-12-2022_04-28-43/model_epoch5.pt\n",
      "======== Epoch 7 / 10 ========\n",
      "Training...\n",
      "[TRAIN] Epoch 6/10 | Batch 0/134 | Train Loss=0.5498378276824951 | Train Acc=0.875\n",
      "[TRAIN] Epoch 6/10 | Batch 100/134 | Train Loss=0.012489302083849907 | Train Acc=1.0\n",
      " Train Accuracy: 0.9823\n",
      " Train F1 score: 0.9776\n",
      " Train Loss: 0.0884\n",
      "Running Validation...\n",
      " Valid Loss: 0.6724\n",
      " Valid Accuracy: 0.8702\n",
      " Valid F1 score: 0.8261\n",
      "Model saved to ==> 12-12-2022_04-28-43/model_best_valoss.pt\n",
      "Model saved to ==> 12-12-2022_04-28-43/model_epoch6.pt\n",
      "======== Epoch 8 / 10 ========\n",
      "Training...\n",
      "[TRAIN] Epoch 7/10 | Batch 0/134 | Train Loss=0.5506923198699951 | Train Acc=0.875\n",
      "[TRAIN] Epoch 7/10 | Batch 100/134 | Train Loss=0.009374049492180347 | Train Acc=1.0\n",
      " Train Accuracy: 0.9841\n",
      " Train F1 score: 0.9771\n",
      " Train Loss: 0.0683\n",
      "Running Validation...\n",
      " Valid Loss: 0.6912\n",
      " Valid Accuracy: 0.8571\n",
      " Valid F1 score: 0.7987\n",
      "Model saved to ==> 12-12-2022_04-28-43/model_best_valoss.pt\n",
      "Model saved to ==> 12-12-2022_04-28-43/model_epoch7.pt\n",
      "======== Epoch 9 / 10 ========\n",
      "Training...\n",
      "[TRAIN] Epoch 8/10 | Batch 0/134 | Train Loss=0.3631192445755005 | Train Acc=0.9375\n",
      "[TRAIN] Epoch 8/10 | Batch 100/134 | Train Loss=0.006368657574057579 | Train Acc=1.0\n",
      " Train Accuracy: 0.9874\n",
      " Train F1 score: 0.9846\n",
      " Train Loss: 0.0562\n",
      "Running Validation...\n",
      " Valid Loss: 0.7383\n",
      " Valid Accuracy: 0.8619\n",
      " Valid F1 score: 0.8183\n",
      "Model saved to ==> 12-12-2022_04-28-43/model_best_valoss.pt\n",
      "Model saved to ==> 12-12-2022_04-28-43/model_epoch8.pt\n",
      "======== Epoch 10 / 10 ========\n",
      "Training...\n",
      "[TRAIN] Epoch 9/10 | Batch 0/134 | Train Loss=0.29849064350128174 | Train Acc=0.9375\n",
      "[TRAIN] Epoch 9/10 | Batch 100/134 | Train Loss=0.005062832497060299 | Train Acc=1.0\n",
      " Train Accuracy: 0.9925\n",
      " Train F1 score: 0.9904\n",
      " Train Loss: 0.0353\n",
      "Running Validation...\n",
      " Valid Loss: 0.8069\n",
      " Valid Accuracy: 0.8482\n",
      " Valid F1 score: 0.7895\n",
      "Model saved to ==> 12-12-2022_04-28-43/model_best_valoss.pt\n",
      "Model saved to ==> 12-12-2022_04-28-43/model_epoch9.pt\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "classes = pd.get_dummies(y_train).columns.tolist()\n",
    "\n",
    "#     train_path = 'train.txt'\n",
    "#     test_path = 'test.txt'\n",
    "\n",
    "MAX_LEN = 256\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
    "\n",
    "train_dataloader = dataloader_from_text(texts=X_train.tolist(), y=y_train.tolist(), tokenizer=tokenizer, classes=classes, savetodisk=None, max_len=MAX_LEN, batch_size=16)\n",
    "valid_dataloader = dataloader_from_text(texts=X_val.tolist(), y=y_val.tolist(), tokenizer=tokenizer, classes=classes, savetodisk=None, max_len=MAX_LEN, batch_size=16)\n",
    "test_dataloader = dataloader_from_text(texts=X_test.tolist(), y=y_test.tolist(), tokenizer=tokenizer, classes=classes, savetodisk=None, max_len=MAX_LEN, batch_size=16)\n",
    "\n",
    "#bert model\n",
    "bert_classifier_model = BERTClassifier(len(classes))\n",
    "#train model\n",
    "bert_classifier_trainer = ClassifierTrainner(bert_model=bert_classifier_model, train_dataloader=train_dataloader, valid_dataloader=valid_dataloader, epochs=10, cuda_device=\"0\") #cuda_device: \"cpu\"=cpu hoac 0=gpu0, 1=gpu1, \n",
    "bert_classifier_trainer.train_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9ff9ac9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T04:38:53.550770Z",
     "iopub.status.busy": "2022-12-12T04:38:53.550468Z",
     "iopub.status.idle": "2022-12-12T04:38:58.830561Z",
     "shell.execute_reply": "2022-12-12T04:38:58.828827Z"
    },
    "papermill": {
     "duration": 5.299545,
     "end_time": "2022-12-12T04:38:58.833738",
     "exception": false,
     "start_time": "2022-12-12T04:38:53.534193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                  Other       0.60      0.75      0.67        80\n",
      "       du-lich_diem-den       0.98      0.88      0.93        59\n",
      "      giai-tri_gioi-sao       0.96      0.91      0.94        57\n",
      "       giao-duc_tin-tuc       0.86      0.89      0.88        57\n",
      "       khoa-hoc_tin-tuc       0.96      0.89      0.92        55\n",
      "      suc-khoe_cac-benh       0.78      0.83      0.80        46\n",
      "       suc-khoe_tin-tuc       0.88      0.75      0.81        69\n",
      "       the-thao_bong-da       0.87      0.84      0.85        62\n",
      "  the-thao_cac-mon-khac       0.91      0.96      0.94        55\n",
      "the-thao_world-cup-2022       0.85      0.80      0.82        55\n",
      "\n",
      "               accuracy                           0.85       595\n",
      "              macro avg       0.87      0.85      0.86       595\n",
      "           weighted avg       0.86      0.85      0.85       595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "bert_classifier_trainer.predict_test(dataloader=test_dataloader, classes=classes, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb47df07",
   "metadata": {
    "papermill": {
     "duration": 0.014876,
     "end_time": "2022-12-12T04:38:58.865890",
     "exception": false,
     "start_time": "2022-12-12T04:38:58.851014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 740.641247,
   "end_time": "2022-12-12T04:39:01.609366",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-12T04:26:40.968119",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0c2f20b7d4144368ac5608ee5646d7c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8c570f090a3046c5bb9cee668206b05e",
       "placeholder": "​",
       "style": "IPY_MODEL_bc81a0e9fb424b2faf9829c8f073beda",
       "value": "Downloading: 100%"
      }
     },
     "0e1fd63b0d76450a83922f382e1d67ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1281df83ae14453b931dbe44da9a3cc7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e88be7a92f364a3e956f168efa712c95",
       "max": 1135173.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e077ae10b56f443f83b8fef1d8374d11",
       "value": 1135173.0
      }
     },
     "161b573cbc4243708e6b0a00807c6add": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2aeeea11f78c43289cd70d6749a88ee0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3b13baa597b9444e9c1fd5915278f766": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3f9dc767b4f14896a4735a91dfda7626": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "656f47c1bf204a41aea94a349e1a7359": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "68c2a9589b7a4b6a9ac8e9c81c7d01a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "69e2cbbd98cd4bd2bf241f0bb4e18cc3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_757a2f3e1cf047d4bc459e448950667e",
       "max": 895321.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0e1fd63b0d76450a83922f382e1d67ef",
       "value": 895321.0
      }
     },
     "6e59812039914bfd9fc4a3a30e4eb900": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "757a2f3e1cf047d4bc459e448950667e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7ba3adb205684ac8971d53e125d52434": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "82a4138d960a4e90983e516b26afab9b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ee576cc9d51e4671a009f2feaf35c953",
        "IPY_MODEL_b1575f4a7fec4da9b8ec49b0750a6b0b",
        "IPY_MODEL_b415949722664cd3a28f7e30700cc961"
       ],
       "layout": "IPY_MODEL_3f9dc767b4f14896a4735a91dfda7626"
      }
     },
     "840d4f05bdbe42c7b7213562164fb334": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ac58904ac54b43e0bac4aa27c6225dff",
       "placeholder": "​",
       "style": "IPY_MODEL_e5eecdb01cb54993ac573ac3537a7b5d",
       "value": " 1.08M/1.08M [00:00&lt;00:00, 2.08MB/s]"
      }
     },
     "859d36dcf05e402eb3f5e2ffcd6df07c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8c570f090a3046c5bb9cee668206b05e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8fbf31f8c1fe483fa0ec4396577da7fa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9304841668d14fdb8266c8a8613239fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0c2f20b7d4144368ac5608ee5646d7c6",
        "IPY_MODEL_69e2cbbd98cd4bd2bf241f0bb4e18cc3",
        "IPY_MODEL_c37d2b20d0ed45258a6f39053effa44b"
       ],
       "layout": "IPY_MODEL_3b13baa597b9444e9c1fd5915278f766"
      }
     },
     "ac58904ac54b43e0bac4aa27c6225dff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b1575f4a7fec4da9b8ec49b0750a6b0b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7ba3adb205684ac8971d53e125d52434",
       "max": 557.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2aeeea11f78c43289cd70d6749a88ee0",
       "value": 557.0
      }
     },
     "b415949722664cd3a28f7e30700cc961": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_161b573cbc4243708e6b0a00807c6add",
       "placeholder": "​",
       "style": "IPY_MODEL_68c2a9589b7a4b6a9ac8e9c81c7d01a5",
       "value": " 557/557 [00:00&lt;00:00, 21.1kB/s]"
      }
     },
     "bc81a0e9fb424b2faf9829c8f073beda": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c265c3b9b5614e689329c7e97028ff8a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c37d2b20d0ed45258a6f39053effa44b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8fbf31f8c1fe483fa0ec4396577da7fa",
       "placeholder": "​",
       "style": "IPY_MODEL_859d36dcf05e402eb3f5e2ffcd6df07c",
       "value": " 874k/874k [00:00&lt;00:00, 1.29MB/s]"
      }
     },
     "ca8b33ee4a494fe0a7f240cfb85a8946": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e40160b7a7ef4afe921429537e509952",
        "IPY_MODEL_1281df83ae14453b931dbe44da9a3cc7",
        "IPY_MODEL_840d4f05bdbe42c7b7213562164fb334"
       ],
       "layout": "IPY_MODEL_656f47c1bf204a41aea94a349e1a7359"
      }
     },
     "db6cffe60c4d415f91083c8c5e566f21": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e077ae10b56f443f83b8fef1d8374d11": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e40160b7a7ef4afe921429537e509952": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c265c3b9b5614e689329c7e97028ff8a",
       "placeholder": "​",
       "style": "IPY_MODEL_6e59812039914bfd9fc4a3a30e4eb900",
       "value": "Downloading: 100%"
      }
     },
     "e5eecdb01cb54993ac573ac3537a7b5d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e88be7a92f364a3e956f168efa712c95": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ee576cc9d51e4671a009f2feaf35c953": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_db6cffe60c4d415f91083c8c5e566f21",
       "placeholder": "​",
       "style": "IPY_MODEL_eedb01e5e5ab4cec92dea1ca52b788ce",
       "value": "Downloading: 100%"
      }
     },
     "eedb01e5e5ab4cec92dea1ca52b788ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
